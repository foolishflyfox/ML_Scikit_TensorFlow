<!DOCTYPE html>
  <html>
    <head>
      <title>用Scikit-Learn和TensorFlow实践机器学习</title>
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width, initial-scale=1.0">
      
      <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.8.3/katex.min.css">
      
      
      
      
      
      
      
      
      

      <style> 
      /**
 * prism.js Github theme based on GitHub's theme.
 * @author Sam Clarke
 */
code[class*="language-"],
pre[class*="language-"] {
  color: #333;
  background: none;
  font-family: Consolas, "Liberation Mono", Menlo, Courier, monospace;
  text-align: left;
  white-space: pre;
  word-spacing: normal;
  word-break: normal;
  word-wrap: normal;
  line-height: 1.4;

  -moz-tab-size: 8;
  -o-tab-size: 8;
  tab-size: 8;

  -webkit-hyphens: none;
  -moz-hyphens: none;
  -ms-hyphens: none;
  hyphens: none;
}

/* Code blocks */
pre[class*="language-"] {
  padding: .8em;
  overflow: auto;
  /* border: 1px solid #ddd; */
  border-radius: 3px;
  /* background: #fff; */
  background: #f5f5f5;
}

/* Inline code */
:not(pre) > code[class*="language-"] {
  padding: .1em;
  border-radius: .3em;
  white-space: normal;
  background: #f5f5f5;
}

.token.comment,
.token.blockquote {
  color: #969896;
}

.token.cdata {
  color: #183691;
}

.token.doctype,
.token.punctuation,
.token.variable,
.token.macro.property {
  color: #333;
}

.token.operator,
.token.important,
.token.keyword,
.token.rule,
.token.builtin {
  color: #a71d5d;
}

.token.string,
.token.url,
.token.regex,
.token.attr-value {
  color: #183691;
}

.token.property,
.token.number,
.token.boolean,
.token.entity,
.token.atrule,
.token.constant,
.token.symbol,
.token.command,
.token.code {
  color: #0086b3;
}

.token.tag,
.token.selector,
.token.prolog {
  color: #63a35c;
}

.token.function,
.token.namespace,
.token.pseudo-element,
.token.class,
.token.class-name,
.token.pseudo-class,
.token.id,
.token.url-reference .token.variable,
.token.attr-name {
  color: #795da3;
}

.token.entity {
  cursor: help;
}

.token.title,
.token.title .token.punctuation {
  font-weight: bold;
  color: #1d3e81;
}

.token.list {
  color: #ed6a43;
}

.token.inserted {
  background-color: #eaffea;
  color: #55a532;
}

.token.deleted {
  background-color: #ffecec;
  color: #bd2c00;
}

.token.bold {
  font-weight: bold;
}

.token.italic {
  font-style: italic;
}


/* JSON */
.language-json .token.property {
  color: #183691;
}

.language-markup .token.tag .token.punctuation {
  color: #333;
}

/* CSS */
code.language-css,
.language-css .token.function {
  color: #0086b3;
}

/* YAML */
.language-yaml .token.atrule {
  color: #63a35c;
}

code.language-yaml {
  color: #183691;
}

/* Ruby */
.language-ruby .token.function {
  color: #333;
}

/* Markdown */
.language-markdown .token.url {
  color: #795da3;
}

/* Makefile */
.language-makefile .token.symbol {
  color: #795da3;
}

.language-makefile .token.variable {
  color: #183691;
}

.language-makefile .token.builtin {
  color: #0086b3;
}

/* Bash */
.language-bash .token.keyword {
  color: #0086b3;
}html body{font-family:"Helvetica Neue",Helvetica,"Segoe UI",Arial,freesans,sans-serif;font-size:16px;line-height:1.6;color:#333;background-color:#fff;overflow:initial;box-sizing:border-box;word-wrap:break-word}html body>:first-child{margin-top:0}html body h1,html body h2,html body h3,html body h4,html body h5,html body h6{line-height:1.2;margin-top:1em;margin-bottom:16px;color:#000}html body h1{font-size:2.25em;font-weight:300;padding-bottom:.3em}html body h2{font-size:1.75em;font-weight:400;padding-bottom:.3em}html body h3{font-size:1.5em;font-weight:500}html body h4{font-size:1.25em;font-weight:600}html body h5{font-size:1.1em;font-weight:600}html body h6{font-size:1em;font-weight:600}html body h1,html body h2,html body h3,html body h4,html body h5{font-weight:600}html body h5{font-size:1em}html body h6{color:#5c5c5c}html body strong{color:#000}html body del{color:#5c5c5c}html body a:not([href]){color:inherit;text-decoration:none}html body a{color:#08c;text-decoration:none}html body a:hover{color:#00a3f5;text-decoration:none}html body img{max-width:100%}html body>p{margin-top:0;margin-bottom:16px;word-wrap:break-word}html body>ul,html body>ol{margin-bottom:16px}html body ul,html body ol{padding-left:2em}html body ul.no-list,html body ol.no-list{padding:0;list-style-type:none}html body ul ul,html body ul ol,html body ol ol,html body ol ul{margin-top:0;margin-bottom:0}html body li{margin-bottom:0}html body li.task-list-item{list-style:none}html body li>p{margin-top:0;margin-bottom:0}html body .task-list-item-checkbox{margin:0 .2em .25em -1.8em;vertical-align:middle}html body .task-list-item-checkbox:hover{cursor:pointer}html body blockquote{margin:16px 0;font-size:inherit;padding:0 15px;color:#5c5c5c;border-left:4px solid #d6d6d6}html body blockquote>:first-child{margin-top:0}html body blockquote>:last-child{margin-bottom:0}html body hr{height:4px;margin:32px 0;background-color:#d6d6d6;border:0 none}html body table{margin:10px 0 15px 0;border-collapse:collapse;border-spacing:0;display:block;width:100%;overflow:auto;word-break:normal;word-break:keep-all}html body table th{font-weight:bold;color:#000}html body table td,html body table th{border:1px solid #d6d6d6;padding:6px 13px}html body dl{padding:0}html body dl dt{padding:0;margin-top:16px;font-size:1em;font-style:italic;font-weight:bold}html body dl dd{padding:0 16px;margin-bottom:16px}html body code{font-family:Menlo,Monaco,Consolas,'Courier New',monospace;font-size:.85em !important;color:#000;background-color:#f0f0f0;border-radius:3px;padding:.2em 0}html body code::before,html body code::after{letter-spacing:-0.2em;content:"\00a0"}html body pre>code{padding:0;margin:0;font-size:.85em !important;word-break:normal;white-space:pre;background:transparent;border:0}html body .highlight{margin-bottom:16px}html body .highlight pre,html body pre{padding:1em;overflow:auto;font-size:.85em !important;line-height:1.45;border:#d6d6d6;border-radius:3px}html body .highlight pre{margin-bottom:0;word-break:normal}html body pre code,html body pre tt{display:inline;max-width:initial;padding:0;margin:0;overflow:initial;line-height:inherit;word-wrap:normal;background-color:transparent;border:0}html body pre code:before,html body pre tt:before,html body pre code:after,html body pre tt:after{content:normal}html body p,html body blockquote,html body ul,html body ol,html body dl,html body pre{margin-top:0;margin-bottom:16px}html body kbd{color:#000;border:1px solid #d6d6d6;border-bottom:2px solid #c7c7c7;padding:2px 4px;background-color:#f0f0f0;border-radius:3px}@media print{html body{background-color:#fff}html body h1,html body h2,html body h3,html body h4,html body h5,html body h6{color:#000;page-break-after:avoid}html body blockquote{color:#5c5c5c}html body pre{page-break-inside:avoid}html body table{display:table}html body img{display:block;max-width:100%;max-height:100%}html body pre,html body code{word-wrap:break-word;white-space:pre}}.markdown-preview{width:100%;height:100%;box-sizing:border-box}.markdown-preview .pagebreak,.markdown-preview .newpage{page-break-before:always}.markdown-preview pre.line-numbers{position:relative;padding-left:3.8em;counter-reset:linenumber}.markdown-preview pre.line-numbers>code{position:relative}.markdown-preview pre.line-numbers .line-numbers-rows{position:absolute;pointer-events:none;top:1em;font-size:100%;left:0;width:3em;letter-spacing:-1px;border-right:1px solid #999;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none}.markdown-preview pre.line-numbers .line-numbers-rows>span{pointer-events:none;display:block;counter-increment:linenumber}.markdown-preview pre.line-numbers .line-numbers-rows>span:before{content:counter(linenumber);color:#999;display:block;padding-right:.8em;text-align:right}.markdown-preview .mathjax-exps .MathJax_Display{text-align:center !important}.markdown-preview:not([for="preview"]) .code-chunk .btn-group{display:none}.markdown-preview:not([for="preview"]) .code-chunk .status{display:none}.markdown-preview:not([for="preview"]) .code-chunk .output-div{margin-bottom:16px}.scrollbar-style::-webkit-scrollbar{width:8px}.scrollbar-style::-webkit-scrollbar-track{border-radius:10px;background-color:transparent}.scrollbar-style::-webkit-scrollbar-thumb{border-radius:5px;background-color:rgba(150,150,150,0.66);border:4px solid rgba(150,150,150,0.66);background-clip:content-box}html body[for="html-export"]:not([data-presentation-mode]){position:relative;width:100%;height:100%;top:0;left:0;margin:0;padding:0;overflow:auto}html body[for="html-export"]:not([data-presentation-mode]) .markdown-preview{position:relative;top:0}@media screen and (min-width:914px){html body[for="html-export"]:not([data-presentation-mode]) .markdown-preview{padding:2em calc(50% - 457px)}}@media screen and (max-width:914px){html body[for="html-export"]:not([data-presentation-mode]) .markdown-preview{padding:2em}}@media screen and (max-width:450px){html body[for="html-export"]:not([data-presentation-mode]) .markdown-preview{font-size:14px !important;padding:1em}}@media print{html body[for="html-export"]:not([data-presentation-mode]) #sidebar-toc-btn{display:none}}html body[for="html-export"]:not([data-presentation-mode]) #sidebar-toc-btn{position:fixed;bottom:8px;left:8px;font-size:28px;cursor:pointer;color:inherit;z-index:99;width:32px;text-align:center;opacity:.4}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] #sidebar-toc-btn{opacity:1}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc{position:fixed;top:0;left:0;width:300px;height:100%;padding:32px 0 48px 0;font-size:14px;box-shadow:0 0 4px rgba(150,150,150,0.33);box-sizing:border-box;overflow:auto;background-color:inherit}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc::-webkit-scrollbar{width:8px}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc::-webkit-scrollbar-track{border-radius:10px;background-color:transparent}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc::-webkit-scrollbar-thumb{border-radius:5px;background-color:rgba(150,150,150,0.66);border:4px solid rgba(150,150,150,0.66);background-clip:content-box}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc a{text-decoration:none}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc ul{padding:0 1.6em;margin-top:.8em}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc li{margin-bottom:.8em}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc ul{list-style-type:none}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .markdown-preview{left:300px;width:calc(100% -  300px);padding:2em calc(50% - 457px -  150px);margin:0;box-sizing:border-box}@media screen and (max-width:1274px){html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .markdown-preview{padding:2em}}@media screen and (max-width:450px){html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .markdown-preview{width:100%}}html body[for="html-export"]:not([data-presentation-mode]):not([html-show-sidebar-toc]) .markdown-preview{left:50%;transform:translateX(-50%)}html body[for="html-export"]:not([data-presentation-mode]):not([html-show-sidebar-toc]) .md-sidebar-toc{display:none}
/* Please visit the URL below for more information: */
/*   https://shd101wyy.github.io/markdown-preview-enhanced/#/customize-css */
 
      </style>
    </head>
    <body for="html-export">
      <div class="mume markdown-preview   ">
      <h1 class="mume-header" id="%E7%94%A8scikit-learn%E5%92%8Ctensorflow%E5%AE%9E%E8%B7%B5%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0">用Scikit-Learn和TensorFlow实践机器学习</h1>

<p>@(Python)[python库, 机器学习, Scikit-learn, TensorFlow]</p>
<blockquote>
<p>观点、工具和技术，建立一个智能系统</p>
</blockquote>
<p><strong>译者所用的Python版本号为3.6.2，原书中的很多代码已经在该版本的Python下不能正常运行，故在翻译的同时做了少量修改</strong></p>
<ul>
<li><a href="#%E7%94%A8scikit-learn%E5%92%8Ctensorflow%E5%AE%9E%E8%B7%B5%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0">用Scikit-Learn和TensorFlow实践机器学习</a>
<ul>
<li><a href="#%E5%89%8D%E8%A8%80">前言</a>
<ul>
<li><a href="#%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%B5%B7%E5%95%B8">机器学习的海啸</a></li>
<li><a href="#%E4%BD%A0%E9%A1%B9%E7%9B%AE%E4%B8%AD%E7%9A%84%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0">你项目中的机器学习</a></li>
<li><a href="#%E7%9B%AE%E6%A0%87%E5%92%8C%E6%96%B9%E6%B3%95">目标和方法</a></li>
<li><a href="#%E5%89%8D%E6%8F%90">前提</a></li>
<li><a href="#%E8%B7%AF%E6%A0%87">路标</a></li>
<li><a href="#%E5%85%B6%E4%BB%96%E8%B5%84%E6%BA%90">其他资源</a></li>
<li><a href="#%E6%9C%AC%E4%B9%A6%E4%B8%AD%E4%BD%BF%E7%94%A8%E7%9A%84%E6%83%AF%E4%BE%8B">本书中使用的惯例</a></li>
<li><a href="#%E4%BD%BF%E7%94%A8%E4%BB%A3%E7%A0%81%E7%A4%BA%E4%BE%8B">使用代码示例</a></li>
<li><a href="#oreilly-safari">O'Reilly Safari</a></li>
<li><a href="#%E5%A6%82%E4%BD%95%E8%81%94%E7%B3%BB%E6%88%91%E4%BB%AC">如何联系我们</a></li>
<li><a href="#%E9%B8%A3%E8%B0%A2">鸣谢</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#%E7%AC%AC%E4%B8%80%E9%83%A8%E5%88%86-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80">第一部分 机器学习基础</a>
<ul>
<li><a href="#%E7%AC%AC%E4%B8%80%E7%AB%A0-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%BA%B5%E8%A7%88">第一章 机器学习纵览</a>
<ul>
<li><a href="#%E4%BB%80%E4%B9%88%E6%98%AF%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0">什么是机器学习？</a></li>
<li><a href="#%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0">为什么要用机器学习</a></li>
<li><a href="#%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%B3%BB%E7%BB%9F%E7%9A%84%E7%A7%8D%E7%B1%BB">机器学习系统的种类</a></li>
<li><a href="#%E7%9B%91%E7%9D%A3%E9%9D%9E%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0">监督/非监督学习</a>
<ul>
<li><a href="#%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0">监督学习</a></li>
<li><a href="#%E9%9D%9E%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0">非监督学习</a></li>
<li><a href="#%E5%8D%8A%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0">半监督学习</a></li>
<li><a href="#%E5%A2%9E%E5%BC%BA%E5%AD%A6%E4%B9%A0">增强学习</a></li>
</ul>
</li>
<li><a href="#%E6%89%B9%E9%87%8F%E5%AD%A6%E4%B9%A0%E5%92%8C%E5%9C%A8%E7%BA%BF%E5%AD%A6%E4%B9%A0">批量学习和在线学习</a>
<ul>
<li><a href="#%E6%89%B9%E9%87%8F%E5%AD%A6%E4%B9%A0">批量学习</a></li>
<li><a href="#%E5%9C%A8%E7%BA%BF%E5%AD%A6%E4%B9%A0">在线学习</a></li>
</ul>
</li>
<li><a href="#%E5%9F%BA%E4%BA%8E%E5%AE%9E%E4%BE%8B-vs-%E5%9F%BA%E4%BA%8E%E6%A8%A1%E5%9E%8B">基于实例 VS 基于模型</a>
<ul>
<li><a href="#%E5%9F%BA%E4%BA%8E%E5%AE%9E%E4%BE%8B%E5%AD%A6%E4%B9%A0">基于实例学习</a></li>
<li><a href="#%E5%9F%BA%E4%BA%8E%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0">基于模型学习</a></li>
</ul>
</li>
<li><a href="#%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E4%B8%BB%E8%A6%81%E6%8C%91%E6%88%98">机器学习的主要挑战</a>
<ul>
<li><a href="#%E8%AE%AD%E7%BB%83%E6%95%B0%E6%8D%AE%E4%B8%8D%E5%85%85%E8%B6%B3">训练数据不充足</a>
<ul>
<li><a href="#%E6%95%B0%E6%8D%AE%E4%B8%8D%E5%8F%AF%E6%80%9D%E8%AE%AE%E7%9A%84%E8%83%BD%E5%8A%9B">数据不可思议的能力</a></li>
</ul>
</li>
<li><a href="#%E9%9D%9E%E5%85%B8%E5%9E%8B%E8%AE%AD%E7%BB%83%E6%95%B0%E6%8D%AE">非典型训练数据</a></li>
<li><a href="#%E4%B8%80%E4%B8%AA%E8%91%97%E5%90%8D%E7%9A%84%E9%87%87%E6%A0%B7%E5%81%8F%E5%B7%AE%E7%9A%84%E4%BE%8B%E5%AD%90">一个著名的采样偏差的例子</a></li>
</ul>
</li>
<li><a href="#%E4%BD%8E%E8%B4%A8%E9%87%8F%E7%9A%84%E6%95%B0%E6%8D%AE">低质量的数据</a></li>
<li><a href="#%E6%97%A0%E5%85%B3%E7%89%B9%E5%BE%81">无关特征</a></li>
<li><a href="#%E8%AE%AD%E7%BB%83%E6%95%B0%E6%8D%AE%E7%9A%84%E8%BF%87%E6%8B%9F%E5%90%88">训练数据的过拟合</a></li>
<li><a href="#%E8%AE%AD%E7%BB%83%E6%95%B0%E6%8D%AE%E7%9A%84%E6%AC%A0%E6%8B%9F%E5%90%88">训练数据的欠拟合</a></li>
<li><a href="#%E5%9B%9E%E9%A1%BE">回顾</a></li>
<li><a href="#%E6%B5%8B%E8%AF%95%E5%92%8C%E9%AA%8C%E8%AF%81">测试和验证</a>
<ul>
<li><a href="#%E6%B2%A1%E6%9C%89%E5%85%8D%E8%B4%B9%E5%8D%88%E9%A4%90%E7%90%86%E8%AE%BA">没有免费午餐理论</a></li>
</ul>
</li>
<li><a href="#%E7%BB%83%E4%B9%A0">练习</a></li>
</ul>
</li>
<li><a href="#%E7%AC%AC%E4%BA%8C%E7%AB%A0-%E4%BB%8E%E5%A4%B4%E5%88%B0%E5%B0%BE%E5%AE%9E%E8%B7%B5%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E9%A1%B9%E7%9B%AE">第二章 从头到尾实践机器学习项目</a>
<ul>
<li><a href="#%E5%B7%A5%E4%BD%9C%E5%9C%A8%E7%9C%9F%E5%AE%9E%E7%9A%84%E6%95%B0%E6%8D%AE%E4%B9%8B%E4%B8%8A">工作在真实的数据之上</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#%E9%99%84%E5%BD%95a-%E7%BB%83%E4%B9%A0%E7%9A%84%E7%AD%94%E6%A1%88">附录A 练习的答案</a>
<ul>
<li><a href="#%E7%AC%AC%E4%B8%80%E7%AB%A0-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%BA%B5%E8%A7%88-1">第一章 机器学习纵览</a></li>
</ul>
</li>
</ul>
<h2 class="mume-header" id="%E5%89%8D%E8%A8%80">前言</h2>

<h3 class="mume-header" id="%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%B5%B7%E5%95%B8">机器学习的海啸</h3>

<p>2006年，Geoffrey Hinton 等人发表了一篇文章，说明了如何通过训练一个深度神经网络的能力来识别手写数字，正确率达到了惊人的98% 。他们称这种技术为 <strong>深度学习</strong>。在当时，训练一个深度神经网络被广泛认为是不可能的，因此，大多数人从19世纪90年代就放弃了这种想法。这篇论文重新勾起了科学社区对深度学习的兴趣。新论文的不断涌现，展示了深度学习不仅可能用于应用，而且其令人兴奋的成绩是其他的机器学习(ML)技术所不能比拟的（主要得益于现今海量的数据的超大的计算能力）。这种热情很快扩展到机器学习的其他领域。</p>
<p>10年时间匆匆而逝，机器学习也已经征服了很多的产业：现在很多的高科技产品的核心就是机器学习，比如网络搜索结果的排序，智能手机的语音识别、电影的推荐系统、alpha狗的围棋大战，还有汽车的无人驾驶领域。</p>
<h3 class="mume-header" id="%E4%BD%A0%E9%A1%B9%E7%9B%AE%E4%B8%AD%E7%9A%84%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0">你项目中的机器学习</h3>

<p>我想，你应该会对机器学习感兴趣，并且会享受加入到这场盛宴的过程中！</p>
<p>也许你希望赋予自己DIY的机器人一个大脑，使它能够识别人脸，或者学着在四周走来走去。</p>
<p>或者，也许你的公司有着海量的数据（用户的日志，财务数据，生产数据，机器传感器的数据，热线统计数据，HR的报表等等），只要你知道如何去找，你就能从这一大堆的数据中挖掘出隐藏的 “宝石”，比如：</p>
<ul>
<li>将所有消费者划分成多个组，对每个组制定最佳的营销策略</li>
<li>根据消费者的消费记录，推荐其相似类型的产品</li>
<li>自动检测存在欺诈行为的交易</li>
<li>预测下一年的收入</li>
<li>... ...</li>
</ul>
<p>不管你是基于以上的什么原因，你都应该已经决定去学机器学习，并且在你的项目中实现它了。</p>
<p>嗯，很好的想法！</p>
<h3 class="mume-header" id="%E7%9B%AE%E6%A0%87%E5%92%8C%E6%96%B9%E6%B3%95">目标和方法</h3>

<p>该书假定你几乎对机器学习一无所知，它的目标是为你 <em>从数据中学习</em> 的编程中提供必需的概念、直觉和工具。</p>
<p>我们将涉及大量的技术，从最简单、最常用的技术（比如线性回归）到一些经常能赢得比赛的深度学习技术。</p>
<p>与其自己通过动手实现一个简陋的机器学习模型，我们更多的是使用现成的Python框架：</p>
<ul>
<li>
<p><code>Scikit-Learn</code> 非常容易使用，而且它非常高效地实现了许多的机器学习算法，可以说该库大大降低了机器学习的准入门槛。</p>
</li>
<li>
<p><code>TensorFlow</code> 是一个更加复杂的库，该库通过数据流图的方式实现分布式数值计算。它通过分布式计算将计算量分配到成千上万的多GPU服务端，使得高效地训练非常大型的神经网络成为了可能。TensorFlow由Google公司创建，并且支持他们的很多大规模机器学习的应用。该库于2015年11月开源。</p>
</li>
</ul>
<p>本书采用实践的方式，通过具体的可以工作的例子和少量的理论来使读者对机器学习产生直觉上的理解。如果你在阅读该书时没有带上你的笔记本电脑，我们强烈建议通过在线的 Jupyter notebooks （网址为：<a href="https://github.com/ageron/handson-ml">https://github.com/ageron/handson-ml</a> ）上实验例子中的代码。</p>
<h3 class="mume-header" id="%E5%89%8D%E6%8F%90">前提</h3>

<p>本书假定你有一些 Python 的编程经验，并且也熟悉 Python 中的一些主要的科学库 <code>NumPy</code>，<code>Pandas</code> 和 <code>Matplotlib</code> 。</p>
<p>另外，你也需要一些大学级别的数学知识，比如微积分、线性代数、概率论和统计学。</p>
<p>如果你现在还不知道Python，<a href="http://learnpython.org">http://learnpython.org</a> 是一个不错的学习网站。官方教程 <a href="https://www.python.org">https://www.python.org</a> 也是一个非常好的选择。</p>
<p>如果你从来没有用过 Jupyter， 第二章将会引导你安装和基本的使用方法，这是一个你值得拥有的工具。</p>
<p>如果你不熟悉 Python 的科学库，在 Jupyter notebooks 中包含了一些教程，是一些关于线性代数的快速教程。</p>
<h3 class="mume-header" id="%E8%B7%AF%E6%A0%87">路标</h3>

<p>该书组织成两个部分。</p>
<p>第一部分：<strong>机器学习的基础</strong>，包括以下内容：</p>
<ul>
<li>什么是机器学习？它解决的是什么问题？机器学习系统分为哪些类？有哪些基本的概念？</li>
<li>一个经典的机器学习项目需要哪些主要的步骤？</li>
<li>学习如何让模型逼近数据</li>
<li>最优化损失函数</li>
<li>处理、清洗和预处理数据</li>
<li>选择和设计特征</li>
<li>选择一个训练模型，通过交叉验证来调节超参数</li>
<li>机器学习的主要挑战，特别是欠拟合和过拟合（偏差和方差的权衡）</li>
<li>对训练数据进行降维，尽量减少维度灾难的风险</li>
<li>最常用的学习算法：多项式线性回归模型、逻辑回归模型、k近邻模型、支持向量机模型、决策树模型、随机森林和集成方法</li>
</ul>
<p>第二部分：<strong>神经网络和深度学习</strong>，包括如下主题：</p>
<ul>
<li>什么是神经网络？它们有什么优点？</li>
<li>用TensorFlow建立并训练神经网络</li>
<li>最重要的神经网络结构：前馈神经网络（FNN）、卷积神经网络（CNN）、循环神经网络（RNN）、长短期记忆网络（LSTM）和 自编码（auto-encoders）</li>
<li>训练深度神经网络的技术</li>
<li>大数据集的大规模神经网络</li>
<li>增强学习</li>
</ul>
<p>第一部分更多的使用Scikit-Learn库，第二部分主要使用Tensor-Flow。</p>
<p><strong>注意：</strong> 各位同志不要着急入坑：深度学习毫无疑问是在所有的机器学习方法中最令人兴奋的，但首先你应该掌握基础的原理。而且，多数的问题能够通过使用更简单的技术，例如：随机森林、集成方法（将会在第一部分进行讨论）进行很好的解决。深度学习更适合于复杂的问题，例如图像识别、语音识别或者是自然语言处理，对于这些问题，你必须提供足够的数据、计算能力以及耐心。</p>
<h3 class="mume-header" id="%E5%85%B6%E4%BB%96%E8%B5%84%E6%BA%90">其他资源</h3>

<p>学习机器学习的资源有很多，例如吴恩达教授在<a href="https://www.coursera.org/learn/machine-learning/">Coursera 上的机器学习课程</a>，Geoffrey Hinton 等人的<a href="https://www.coursera.org/learn/neural-networks">神经网络与机器学习</a>都非常棒，尽管这些课程都需要投入大量的时间去消化（大概够你想几个月吧）。</p>
<p>关于机器学习，还有许多有趣的网站，包括Scikit-Learn官网上的<a href="http://scikit-learn.org/stable/user_guide.html">用户指南</a>。你也许还会喜欢 <a href="https://www.dataquest.io/">Dataquest</a> 网站，它提供了优雅的交互式教程，想看更多关于机器学习的博客的话，可以查看<a href="https://www.quora.com/What-are-the-best-regularly-updated-machine-learning-blogs-or-resources-available">Quora</a>上的这个列表。最后，<a href="http://deeplearning.net/">Deep Learning website</a>列出了很多优质的资源供你更深入地学习。</p>
<p>当然，还有许多介绍机器学习的书籍，特别需要列出的有：</p>
<ul>
<li>Joel Grus, <a href="http://shop.oreilly.com/product/0636920033400.do">Data Science from Scratch</a>，O'Reilly出版社出版，中文名为《数据科学入门》，该书介绍了机器学习的基本原理，<strong>并用纯Python语言实现了其中主要的算法</strong>（正如书名所说的，从零开始）</li>
<li>Stephen Marsland, <a href="https://book.douban.com/subject/3887824/">Machine Learning: An Algorithmic Perspective</a>，英国的CRC（Chapman and Hall）出版社出版。该书对机器学习的介绍还是很有深度的，也提供了Python 的代码实现（也是从零开始，不过是用Numpy库）</li>
<li>Sebastian Raschka，<a href="https://book.douban.com/subject/26629312/">Python Machine Learning</a>，Packt出版社出版，该书对机器学习的介绍也非常棒，其中的代码实现主要借助了开源的库：Pylearn 2 和 Theano</li>
<li>Yaser S. Abu-Mostafa, Malik Magdon-Ismail, 和 Hsuan-Tien Lin，<a href="https://book.douban.com/subject/11026330/">Learning from Data</a>  AMLBook 出版社出版。该书是对机器学习进行了理论化的介绍，具有非常深刻的见解，特别是第四章的<em>偏差-方差权衡</em></li>
<li>Stuart Russell, Peter Norvig, <a href="https://book.douban.com/subject/5378558/">Artificial Intelligence: A Modern Approach, 3rd Edition</a>。该书真的是一本关于人工智能的大部头的书，而且其中涉及的论题数量也非常惊人，其中包括了机器学习，它能带你从整个人工智能的角度来审视机器学习所处的位置</li>
</ul>
<p>最后，一种 &quot;速成&quot; 的方式是注册一个机器学习比赛网站的账号，比如 <a href="https://www.kaggle.com/">Kaggle.com</a>，它将为你提供解决一个真实世界问题的实践平台，同时也可以得到很多机器学习顶级专家的帮助。</p>
<h3 class="mume-header" id="%E6%9C%AC%E4%B9%A6%E4%B8%AD%E4%BD%BF%E7%94%A8%E7%9A%84%E6%83%AF%E4%BE%8B">本书中使用的惯例</h3>

<p>以下是本书中的使用的印刷规范：</p>
<p>斜体（<em>Italic</em>）<br>
        表示新的术语、URLs、email地址、文件名和文件扩展。</p>
<p>等宽 （<code>Constant width</code>）<br>
       用于程序列表的现实，也可能是出现在段落内的程序元素，比如变量、函数名、数据库、数据类型、环境变量、声明及关键字。</p>
<p>等宽加粗（<strong><code>Constant width</code></strong>）<br>
        用于显示命令或者是其他的用户需要手动逐字输入的文本。</p>
<p>等宽斜体（<em><code>Content width</code></em>）<br>
       用于显示可替换的文本，这些文本需要用户提供或者是需要根据具体的语境生成。</p>
<p><img src="./asset/suggest.png" alt="Alt text"> 该图案表示 <strong>提示</strong> 或 <strong>建议</strong></p>
<p><img src="./asset/note.png" alt="Alt text"> 该图案表示通常的 <strong>注释</strong></p>
<p><img src="./asset/warning.png" alt="Alt text"> 该图案表示一个 <strong>警告</strong> 或 <strong>注意点</strong></p>
<h3 class="mume-header" id="%E4%BD%BF%E7%94%A8%E4%BB%A3%E7%A0%81%E7%A4%BA%E4%BE%8B">使用代码示例</h3>

<p>本书所提供所有材料（包括代码示例、练习等），都可从 <a href="https://github.com/ageron/handson-ml">https://github.com/ageron/handson-ml</a> 下载下来。</p>
<p>本书是为了帮助你刚好地完成工作。所以，如果你需要在你的代码或文档中使用本书提供的案例代码，通常不需要联系我们以获取许可。除非你需要非常大量的代码。例如，如果你仅仅是需要使用几个代码块，自然不需要获取许可。回答问题时引用了示例代码也不需要获得许可。但是，如果需要将大量的实例代码组织起来合并到你的产品文件中，就需要获得我们的许可了。</p>
<p>在使用代码时，我们感激但并不强制注明出处。出处通常应该包括书名，作者，出版社和 ISBN。例如：“<em>Hands-on Machine Learning with Scikit-Learn and TensorFlow</em> by Aurelien Geron (O'Reilly)，Copyright 2017, Aurelien Geron, 978-1-491-96229-9”</p>
<p>如果你感觉自己将其中的代码超过了合理利用的范围，或者是超过了上述的使用权限，敬请联系我们：<a href="permissions@oreilly.com"><em>permissions@oreilly.com</em></a></p>
<h3 class="mume-header" id="oreilly-safari">O'Reilly Safari</h3>

<p><img src="./asset/1516620405430.png" alt="Alt text"><br>
<a href="http://oreilly.com/safari">Safari</a>（原先是Safari Books Online）是一个针对企业、政府机关、教育机构以及个人的基于会员制的培训和参考平台。</p>
<p>会员能够获得上千的书籍、培训视频、学习途径、交互教程以及超过250家出版社的出版清单，包括 O'Reilly Media, Harvard Business Review, Prentice Hall Professional, Addison-Wesley Profes‐ sional, Microsoft Press, Sams, Que, Peachpit Press, Adobe, Focal Press, Cisco Press,ohn Wiley &amp; Sons, Syngress, Morgan Kaufmann, IBM Redbooks, Packt, Adobe Press, FT Press, Apress, Manning, New Riders, McGraw-Hill, Jones &amp; Bartlett 和 Course Technology 等等。</p>
<p>详情请访问：<a href="http://oreilly.com/safari%E3%80%82">http://oreilly.com/safari。</a></p>
<h3 class="mume-header" id="%E5%A6%82%E4%BD%95%E8%81%94%E7%B3%BB%E6%88%91%E4%BB%AC">如何联系我们</h3>

<p>请将关于本书的评论和问题发送到出版社，地址为：</p>
<p>        O’Reilly Media, Inc.<br>
        1005 Gravenstein Highway North<br>
        Sebastopol, CA 95472<br>
        800-998-9938 (in the United States or Canada)<br>
        707-829-0515 (international or local)<br>
        707-829-0104 (fax)</p>
<p>关于本书的勘误表、例子以及如何附加的信息都会放在我们的网站上，地址为：<a href="https://bit.ly/hands-on-machine-learning-with-scikit-learn-and-tensorow%E3%80%82">https://bit.ly/hands-on-machine-learning-with-scikit-learn-and-tensorow。</a></p>
<p>如果想咨询关于本书的技术问题，请发邮件至： <a href="bookques%E2%80%90tions@oreilly.com">bookques‐tions@oreilly.com</a>。</p>
<p>更多的有关我们的出版物、课程、讨论会、新闻的内容，请访问我们的网站：<a href="http://www.oreilly.com">http://www.oreilly.com</a>。</p>
<p>在facebook上找到我们：<a href="http://facebook.com/oreilly">http://facebook.com/oreilly</a></p>
<p>订阅我们的Twitter：<a href="http://twitter.com/oreillymedia">http://twitter.com/oreillymedia</a></p>
<p>在YouTube上找到我们：<a href="http://www.youtube.com/oreillymedia">http://www.youtube.com/oreillymedia</a></p>
<h3 class="mume-header" id="%E9%B8%A3%E8%B0%A2">鸣谢</h3>

<p>我要感谢我在Google公司的同事，特别是YouTube视频分类小组的小伙伴们，你们教会了我那么多关于机器学习的知识，如果没有你们，我将不可能写成这本书。特别的感谢留给我的机器学习导师：Clement Courbet，Julien Dubois，Mathias Kende，Daniel Kitachewsky，James Pack，Alexander Pak，Anosh Raj，Vitor Sessak，Wiktor Tomczak，Ingrid von Glehn，Rich Washington	在 YouTube Pairs 中的每一位。</p>
<p>我也非常感激所有能够在百忙之中抽出时间仔细校对这本书的人。感谢 Pete Warden ，他作为 TensorFlow团队中的核心成员，回答了我所有关于TensorFlow的问题，校对了第二部分，并提供了许多有趣的想法。你一定得去访问一下他的<a href="https://petewarden.com/">博客</a>。感谢Lukas Biewald，他非常彻底的校对了第二部分：测试了所有的代码，提出了许多的建议，他的热情深深感染了我。你应该访问他的<a href="https://lukasbiewald.com/">博客</a> 和他<a href="https://www.oreilly.com/learning/how-to-build-a-robot-that-sees-with-100-and-tensorflow">库库的机器人</a>。感谢 Justin Francis，他完全地校对了第二部分，找出了许多的错误并提供了许多想法，特别是在16章中，可以查看他关于TensorFlow的<a href="https://www.oreilly.com/people/justin-francis">博文</a>。</p>
<p>非常感谢 David Andrzejewski，他校对了第一部分，并提供了大量有用反馈，指出了其中写得含糊不清的部分，并建议如何进行改进，欢迎查看他的<a href="http://www.david-andrzejewski.com/">网站</a>。感谢 Gregoire Mesnil，校对了第二部分，在关于训练神经网络方面贡献了非常有趣和实用的建议。也感谢Eddy Hung，Salim Semaoune，Karim Matrah，Ingrid von Glehn，Iain Smears 和 Vincent Guilbeau，他们校对了第一部分，并提出了许多有用的建议。我也必须感谢我的岳父 Michel Tessier，以及之前是我数学老师现在是优秀的翻译者的 Anton Chekhov，帮助我解决了许多数学以及符号方面的问题，并校验了关于Jupyter notebook线性代数部分的内容。</p>
<p>当然，万分感谢我亲爱的兄弟Sylvain，他校对了每一个章节，并测试了其中的每一行代码，并几乎在每个章节都提供了反馈，并从写书之初到之后都一直支持我。爱你，哥！</p>
<p>非常感谢 O'Reilly 非常棒的工作人员，特别是Nicole Tache，给了我许多富有洞察力的反馈。同时也感谢Marie Beaugureau，Bea Lorica，Mike Loukides 和 Laurel Ruma，一直相信这个项目，并未为本书明确了着眼点。感谢 Matt Hacker 和所有 Atlas 组的成员，回答了我关于格式、asciidoc 和 LaTeX 的问题。感谢Rachel Monaghan，Nick Adams 和所有产品组的成员，帮我完成了最终的审稿并做了许多的改正。</p>
<p>最后但同样重要的，我非常非常感谢我亲爱的妻子，Emmanuelle 和我们3个可爱的孩子，Alexandre，Aemi 和 Gabrielle，鼓励我努力完成这本书，问了我许多的问题（谁说不能教7岁小孩学习神经网络），为我提供饼干和咖啡，有此待遇，夫复何求？</p>
<h1 class="mume-header" id="%E7%AC%AC%E4%B8%80%E9%83%A8%E5%88%86-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80">第一部分 机器学习基础</h1>

<h2 class="mume-header" id="%E7%AC%AC%E4%B8%80%E7%AB%A0-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%BA%B5%E8%A7%88">第一章 机器学习纵览</h2>

<p>大多数人听到 “机器学习” 时，大脑中应该会浮现出一个机器人：可信赖的管家或者是致命的终结者，随你怎么称呼吧。但是机器学习并非仅仅是未来的一个奇迹。事实上，它已经在某些特殊的应用场景中存在了几十年，例如光学字符识别（Optical Character Recognition, OCR）。但是机器学习的应用第一次成为主流，改善千万人的生活需要追溯到上世纪的90年代：垃圾邮件过滤器。它并不是一个有自我意识的天网，但是在技术层面的确是一个合格的机器学习应用（它实际上已经几乎不需要你辅助标出垃圾邮件了）。它被许多的机器学习应用所效仿，并默默影响着从更好的推荐系统到语义检索等成百上千的你所经常使用的功能。</p>
<p>机器学习从何而来，又将归于何处？机器学习到底学的是什么东西？如果我把维基百科下载下来，那是不是我的电脑就称为学到了一些东西？它是突变的智能吗？在本章，我们将阐明什么是机器学习以及为什么你要学习它？</p>
<p>在我们开始探索机器学习这块未知的大陆之前，我们先了解一下它主要的划分和最显著的“路标”：监督学习 vs 非监督学习，在线学习 vs 批量学习。之后，我们将会看到一个典型的机器学习项目的工作流程，讨论你可能需要面对的主要挑战，包括如何去评价和微调一个机器学习系统。</p>
<p>本章将介绍每个数据科学家需要真正理解的许多基本概念（和行话），本章只是一个高度概述（不涉及很多代码），所有的内容都非常简单，但是你应当确保在阅读其他章节之前，对本章的所有内容都非常明白。来杯咖啡，让我们开干吧！</p>
<blockquote>
<p>如果你已经对机器学习的基本概念都了解清楚了，你可以跳到第二章继续阅读。如果你不是非常确定，就在跳转之前先尝试回答在本章最后所列出的所有问题。</p>
</blockquote>
<h3 class="mume-header" id="%E4%BB%80%E4%B9%88%E6%98%AF%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0">什么是机器学习？</h3>

<p>机器学习是计算机编程的科学（和艺术），程序能从数据中进行学习。</p>
<p>以下是一个常见的定义：</p>
<blockquote>
<p>机器学习是不通过显式地编程而让计算机获得某种能力的领域。<br>
------ Arthur Samuel，1959</p>
</blockquote>
<p>而更加工程化的描述为：</p>
<blockquote>
<p>对于某类任务T和性能度量P，如果一个计算机程序在T上以P衡量的性能随着经验E而自我完善，那么我们称这个计算机程序在从经验E学习<br>
------ Tom Mitchell，1997</p>
</blockquote>
<p>比如说，你的垃圾邮件过滤器就是一个机器学习的程序，它能够学着去标记一封邮件是不是垃圾邮件，而最初由用户给这些邮件打上标记供机器学习。供系统使用的所有训练案例称为训练集，每个单独的训练案例称为训练实例（或称为采样）。在这个例子中，任务T就是为一封新邮件打上标记，经验E是训练集中的数据，性能衡量P需要被定义；比如，你可以用邮件分类正确的比率来作为P，这种特殊的性能衡量指标称为正确率，它常常被用于分类的任务中。</p>
<p>如果你只是将维基百科的一个拷贝下载下来，虽然你的电脑有了很多的数据，但是它不会立即具备测试某个实例的能力。因此，这种行为并不是机器学习。</p>
<h3 class="mume-header" id="%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0">为什么要用机器学习</h3>

<p>想象一下，如何用传统的方法来编写邮件过滤器（如图1-1所示）：</p>
<ol>
<li>第一步，你需要确定垃圾邮件的典型特征。你也许会注意到垃圾邮件中经常会出现一些特定的单词或短语（例如 “4U”，“信用卡”，“免费”，“惊人的”），也许你也会注意到垃圾邮件的发送人名字、邮件格式存在一定的规律。我们把这些规律称为模式。</li>
<li>你需要为你所留意到的每一种模式写检测代码，之后你的程序根据检测到这些模式的数量来决策该邮件是否是垃圾邮件。</li>
<li>你需要测试你的程序，然后重复1~2步骤直到结果足够好。</li>
</ol>
<p><img src="./asset/1516630753816.png" alt=""><br>
<em>图1-1. 传统的方法</em></p>
<p>可能找到的模式非常多，因此你的程序看起来就像一张有许多复杂规则的长表——非常难以维护。</p>
<p>相反的，基于机器学习的垃圾邮件分类器能够通过检测垃圾邮件中经常出现而正常邮件中不常见的单词模式，自动地学会什么单词和短语能很好地用于垃圾邮件的预测（图1-2所示）。这个程序更加简短，也更容易维护，而且很有可能预测结果更加准确。</p>
<p><img src="./asset/1516632423698.png" alt="Alt text"><br>
<em>图1-2 机器学习的方式</em></p>
<p>此外，如果垃圾邮件发送者如果发现所有含 “4U” 的邮件都被拦截了，他们可能会开始用“For U” 来替代。用传统方法构建的邮件过滤器将不得不添加一条规则来过滤含 “For U” 的email。如果垃圾邮件发送者针对你的邮件过滤器继续修改，你也必须保证能随之添加新的过滤规则。</p>
<p>相反的，基于机器学习的邮件过滤器自动探测出含 “For U” 的邮件被用户标记为垃圾邮件的频率特别高，之后该过滤器不需要人工介入，就能开始对 “For U” 进行标记（图 1-3）。</p>
<p><img src="./asset/1516634844274.png" alt="Alt text"><br>
<em>图 1-3 自适应变化</em></p>
<p>另一个机器学习能够“发光发热”的领域是某些问题对于传统编程来说太过复杂或者根本没有已知的算法。比如说，语音识别：你要写一个简单的程序，能够根据你说的 “One” 或 “Two” 来将他们区分开来。你也许注意到单词 “Two” 是以高音开头（“T”），因此你可以写一个算法用于测试高音的强度，用这种方法来“One” 和 “Two” 。显然，这种方法并不能推广到成千上万的单词中，而每个人说话的口音也不一样，人们说话的时的环境可能有很多噪音，这些都使得用传统方式做语音识别变得不可能。最好的解决方案（就当前而言）是写一个能自我学习的算法，并提供大量的单词录音供其学习。</p>
<p>最后要说，其实机器学习还能够辅助人类进行学习（图 1-4）：我们可以检查机器学习算法来观察它们到底学到了什么（虽然对于有的算法来说不是很容易）。比如说，邮件分类器在训练了足够多的垃圾邮件之后，能够简单地获取它所认为的有利于预测垃圾邮件的单词列表。有时候，它能够揭示出未知的关联或者新趋势，由此更好地对问题进行理解。</p>
<p><img src="./asset/1516672220378.png" alt="Alt text"><br>
<em>图 1-4 机器学习能够辅助学习某些规律</em></p>
<p>总结来说，机器学习能够用于以下场景：</p>
<ul>
<li>解决某一问题需要花大量时间手动调整代码，或者是该问题有大量的规则：机器学习算法通常代码更简单，效果更好</li>
<li>某些复杂的问题如果使用传统编程方式的话，根本没有好的解决方案：最好的机器学习技术能够找到解决方案</li>
<li>变动的环境：机器学习系统需要能够根据新采集的数据进行自我调整</li>
<li>某个复杂的问题有大量的数据，我们需要找到其中的某些规律</li>
</ul>
<h3 class="mume-header" id="%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%B3%BB%E7%BB%9F%E7%9A%84%E7%A7%8D%E7%B1%BB">机器学习系统的种类</h3>

<p>机器学习系统的种类非常多，我们需要根据以下的几点将它们分成几个大类：</p>
<ul>
<li>它们是不是在有人监督的情况下进行学习（分为监督学习、非监督学习、半监督学习、增强学习）</li>
<li>它们是不是能够在增量式渐进地优化自身（分为在线学习和批量学习）</li>
<li>它们是简单地将新数据和原有数据进行比较来预测，还是像科学家一样从原有数据中发现某些特定的模式，并通过构建一个预测模型来对新数据进行预测（分为基于实例和基于模型）</li>
</ul>
<p>这些分类标准并不是绝对的，你可以用如何你喜欢的方式来对它们进行组合。比如说，一个最先进的邮件分类器也许能够在应用的同时，将新的标有垃圾邮件或普通邮件的案例输入到一个神经网络模型中进行训练；这个系统就称为在线的、基于模型的监督学习系统。</p>
<p>让我们具体看看这些分类标准是什么。</p>
<h3 class="mume-header" id="%E7%9B%91%E7%9D%A3%E9%9D%9E%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0">监督/非监督学习</h3>

<p>机器学习系统能够根据在训练的过程中是否需要监督进行分类。主要可以分为4个类：监督学习，非监督学习，半监督学习和增强学习。</p>
<h4 class="mume-header" id="%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0">监督学习</h4>

<p>在监督学习中，你 “喂” 给机器学习算法的训练数据中包括了你希望得到的结果，称为标记（图 1-5）</p>
<p><img src="./asset/1516675587803.png" alt="Alt text"><br>
<em>图 1-5 监督学习的带标签训练集</em></p>
<p>一种典型的监督学习任务是 <em>分类</em>。邮件分类器就是分类的一个很好的例子：它通过很多带有类型信息（垃圾或者普通）的邮件来学习，之后用于新邮件的分类。</p>
<p>另一种典型的监督学习任务是预测一个数值，比如说一辆车的价格，提供的是大量的特征向量（将里程数、车龄、品牌等不同属性组合在一起成为一个特征向量），这种任务称为 <em>回归</em>（图 1-6）。在训练时，你需要给算法提供很多同时包含特征向量和标记（车价格）的例子。</p>
<p><img src="./asset/1516678371874.png" alt="Alt text"><br>
<em>图 1-6 回归</em></p>
<blockquote>
<p>一个有趣事实是，<em>回归</em> 这个奇怪的名字原本是统计学的一个术语，最开始是Francis Galton 在研究孩子身高时引入，他发现如果一个孩子的父母都是高个子，孩子趋向于比他的父母都要矮，所以他称这种现象为 <em>回归于平均水平</em>。这个名词后来被他用于分析两个相关变量关系的方法中。</p>
</blockquote>
<p><img src="./asset/note.png" alt="Alt text"><br>
在机器学习中，一个 <em>属性</em> 通常是指一种类型的数据（例如里程数），而 <em>特征</em> 需要根据上下文来确定其具体的含义，但通常来说是指一个属性和它的值（例如：“里程数=15,000”）。也有很多人将 <em>属性</em> 和 <em>特征</em> 混用。</p>
<p>**注意：**有的回归算法也会被用于分类，反之亦然。比如说，逻辑回归算法就是一种常见的将回归应用于分类的算法，其输出值为属于相应类的概率大小（例如：20%的可能是垃圾邮件）。</p>
<p>下面是一些最重要的监督学习算法（本书中涵盖的）：</p>
<ul>
<li>k-近邻</li>
<li>线性回归</li>
<li>逻辑回归</li>
<li>支持向量机</li>
<li>决策树和随机森林</li>
<li>神经网络</li>
</ul>
<blockquote>
<p>注意：有的神经网络可能是非监督学习，比如说自编码 (autoencoders)和 受限玻尔兹曼机。有的神经网络也可能是半监督的，比如 深度信念网络（Deep Belief Networks）和 非监督预训练（unsupervised pre-training）</p>
</blockquote>
<h4 class="mume-header" id="%E9%9D%9E%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0">非监督学习</h4>

<p>正如你所料，非监督学习的训练数据不提供标记（图 1-7）。系统在没有 “老师” 的情况下进行学习。<br>
<img src="./asset/1516687036244.png" alt="Alt text"><br>
<em>图 1-7 一个用于非监督学习的无标记训练集</em></p>
<p>下面是一些最重要的非监督学习算法（在第8章，我们将会讲解数据降维）：</p>
<ul>
<li>聚类
<ul>
<li>k-均值（k-Means）</li>
<li>层次聚类分析（Hierarchical Cluster Analysis，HCA）</li>
<li>最大期望算法（Expectation Maximization）</li>
</ul>
</li>
<li>数据降维和可视化
<ul>
<li>主成分分析（Principle Component Analysis，PCA）</li>
<li>核主成分分析（Kernel PCA）</li>
<li>局部线性嵌入（Locally-Linear Embedding，LLE）</li>
<li>t分布随机近邻嵌入（t-distribution stochastic neighbor embedding，t-SNE）</li>
</ul>
</li>
<li>关联规则学习
<ul>
<li>Apriori算法</li>
<li>Eclat算法</li>
</ul>
</li>
</ul>
<p>比如说，你有很多浏览你博客的访问者的数据，你可能希望运行一个聚类算法将相似的访问者划分为同一个组（图 1-8）。你没有对算法说明某个访问者应该属于哪个类，它完全自动地找到他们之间的关联。再比如，你发现访问者中40%是喜欢看连环画的男性，他们通常在晚上读你的博客，而20%是喜欢读科幻小说的年轻人，他们通常在周末浏览你的博客，等等。如果你使用层次聚类算法，还可能将每个组再细分为更小的组。这些信息可以帮助你针对每一个组推送他们喜欢的博文。</p>
<p><img src="./asset/figure1_8.png" alt="Alt text"><br>
<em>图 1-8 聚类</em></p>
<p>可视化算法也是非监督学习算法的一个很好的例子：你提供了大量复杂且无标记的数据，算法输出能够在2维或3维图像中非常容易显示的数据（图1-9）。这些算法尽可能多地保留数据原有的结构关系（例如：试图在可视化操作中保持分离的集群尽可能不重叠），让你能理解数据是如何组织的，并发现其中潜在的规律。<br>
<img src="./asset/1516691230759.png" alt="Alt text"><br>
<em>图 1-9 t-SNE 语义集群的高亮可视化显示</em></p>
<blockquote>
<p>从图中你可以看到，动物和交通工具有非常明显的分界，而 “horse” 与 “deer” 的距离要比其与 “bird” 的距离近，等等信息。<br>
图片来自于 Socher，Ganjoo，Manning 和 Ng (2013), &quot;T-SNE visualization of the semantic word space&quot;，已通过授权。</p>
</blockquote>
<p>与聚类相关的一个任务是 <em>数据降维</em>，目的是在简化数据的同时尽可能减少信息量的损失。一种实现方式是将多个相关的特征合并为一个特征。比如，车的里程数和车龄非常相关，因此可以把这两个特征合并成一个特征，表示车的磨损程度。这就称为 <em>特征提取</em> 。</p>
<p><strong>通常来说，在将数据交个某个机器学习算法（比如监督学习算法）进行训练之前，先用数据降维算法减小原始数据的维度是一个很好的想法。而且也能让训练的时间更短，数据占用的磁盘和内存资源更少，而且有时候能够获得更好的训练结果</strong></p>
<p>还有一个非监督学习的任务是 <em>异态检测</em>，例如：发现信用卡的非正常交易以预防诈骗，发现生产中的次品，在将数据集交个学习算法进行训练之前先删除其中的异常值。这个系统使用正常的实例进行训练，当一个新的实例到来，它能判断该实例是正常的还是异常的（见图 1-10）。<br>
<img src="./asset/1516694354177.png" alt="Alt text"><br>
<em>图 1-10 异态检测</em></p>
<p>最后一个常见的非监督学习任务是 <em>关联规则学习</em>，主要用于挖掘数据，发现各属性之间的有价值的关系。比如说，假设你开了一家超市，将你每一天的销售记录交给关联规则学习算法处理，可能会发现买了烧烤调料和薯片的人很可能同时买牛排。因此，你可以将这些商品放在一起，可能就会提高营业收入。</p>
<h4 class="mume-header" id="%E5%8D%8A%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0">半监督学习</h4>

<p>有的算法能够处理部分标记的训练数据，通常是大多数未标记，只有少量做了标记。这总算法就是半监督算法（图 1-11）。</p>
<p><img src="./asset/1516697460215.png" alt="Alt text"><br>
<em>图 1-11 半监督学习</em></p>
<p>某些图片托管服务，如 Google Photos，就是这种算法的一个例子。如果你向服务器上传了一张你的全家福照片，它就能自动识别其中的人，并指出某人A出现在第1、5、11张图片中，另一个人B出现在第2、5、7张图片中。这部分工作属于非监督学习算法（聚类）。现在，这个系统的工作是，在这张全家福的照片中指出他们分别是谁，即仅仅是对一个样本打上标签，它就能说出每一张照片上每个人的名字，这对照片的检索非常有用。</p>
<blockquote>
<p>注：上述情况只有在系统工作得非常完美时才会出现。但实际情况是，系统经常会给同一个人创建多个类别，或者有的时候在同一个类别中会有两个或多个看起来长得像的人，所以，你需要一些个人单独的照片，并且手动清除一些类别。</p>
</blockquote>
<p>大多数的半监督学习算法同时结合了非监督学习和监督学习算法。比如 <em>深度信念网络 (DBNS)</em> 就是在非监督算法 <em>受限玻尔兹曼机(RBMs)</em> 的基础上再加一层或多层的 RBMs，以非监督的方式按顺序用RBMs进行训练，之后，整个系统使用监督学习的方法进行调优。</p>
<h4 class="mume-header" id="%E5%A2%9E%E5%BC%BA%E5%AD%A6%E4%B9%A0">增强学习</h4>

<p>和之前的机器学习算法相比，增强学习绝对是一个异类。在该学习系统中，有一个称为 <em>代理</em> 的模块，能够对当前的环境进行 “观察”，选择并执行某个动作，并返回一个奖励（或者是返回一个惩罚作为消极的反馈，如图 1-12）。系统必须能够自动地学会什么是最佳的动作，称为策略，即获得奖励最多的那个动作。一个策略指定了在某种给定的情形下，代理应该如何选择。</p>
<p><img src="./asset/1516704325739.png" alt="Alt text"><br>
<em>图 1-12 增强学习</em></p>
<p>举例来说，许多的机器人都实现了增强学习算法用于学习走路。DeepMind项目的AlphaGo程序就是增强学习的一个很好的例子：它在2016年3月的时候，凭借着战胜世界围棋冠军的李世石而一举成名。它通过分析上百万的围棋对弈过程，学到了赢棋的策略，之后开始与自身进行对弈。在真正的对弈开始时，系统并不进行学习，而是将其已经学到的策略进行应用。</p>
<h3 class="mume-header" id="%E6%89%B9%E9%87%8F%E5%AD%A6%E4%B9%A0%E5%92%8C%E5%9C%A8%E7%BA%BF%E5%AD%A6%E4%B9%A0">批量学习和在线学习</h3>

<p>另一种用于对机器学习进行分类的标准是：随着在数据流的不断到来，系统能否循序渐进地改善自身的性能。</p>
<h4 class="mume-header" id="%E6%89%B9%E9%87%8F%E5%AD%A6%E4%B9%A0">批量学习</h4>

<p><em>批量学习</em> 并不具备循序渐进改善自身的能力：它在训练时，必须一次性输入所有当前可得到的数据。通常来说，这需要花费大量的时间和计算资源，因此它通常是离线进行的。首先，完成对系统的训练，接下来讲系统安装到生产环境中，并且在应用的过程中不再进行学习；它只是简单地将学到的 “知识” 进行应用，这也叫做 <em>离线学习</em>。</p>
<p>如果你希望批量学习系统能够正确处理 “变种” 的数据（比如出现了新的垃圾邮件模式），你需要从头开始用所有的数据重新训练一个新版本的系统（不仅仅是新的数据，而且也要包括原有数据），之后，用新训练的系统替换掉老系统。</p>
<p>幸运的是，整个过程包括训练、性能评估、系统的更换都能非常简单地自动化进行（如图 1-3 所示），所以批量学习也能够适应不断变化的数据。只要根据需求，定期地更新训练数据并从头开始训练一个新版本的系统即可。</p>
<p>这种解决方案通常来说简单并且有效，但是用所有的数据进行训练很可能需要花费数个小时，所以你通常只是每24小时或者是每个星期训练一个新的系统。如果你的系统需要快速适应不断变化的数据（比如预测股票价格），那你就需要一个使系统进化更快的解决方案。</p>
<p>另外，训练所有的数据需要大量的计算资源（CPU、内存空间、磁盘空间、网络资源等等）。如果训练集中的数据量非常大，而你的系统需要每天都从头开始进行自动训练，它最终将消耗你大量的资金。如果数据的量超级巨大，那使用批量学习根本就是不现实的。</p>
<p>最后，如果你的批量学习系统安装在一个资源有限的设备上（如智能手机或火星探测器），每天带着大量的训练数据，占用大量资源训练多个小时，那么这个设备估计其他什么事情都干不了了。</p>
<p>幸运的是，在上述那些尴尬的情况下，我们可以使用接下来介绍的算法实现循环渐进的学习。</p>
<h4 class="mume-header" id="%E5%9C%A8%E7%BA%BF%E5%AD%A6%E4%B9%A0">在线学习</h4>

<p>在线学习系统中，你可以将数据一个一个，或者一小组一小组地 “喂” 给你的系统（每一小组称为 <em>小批</em> ），你系统的性能也在你喂食的过程中渐渐得到优化。这样学习的每一步都非常快速，代价也小，因此系统能够在运行的同时，对新来的数据进行学习（见图 1-13）。</p>
<p><img src="./asset/1516711944382.png" alt="Alt text"><br>
<em>图 1-13 在线学习</em></p>
<p>在线学习算法非常适合于数据以流的方式连续不断到来的系统（如股票的价格）和需要快速适应改变的系统。当然，如果你只有为数不多的计算资源，那么在线学习也是一个很好的选择：一旦在线学习系统学过了新的实例，它就不需要再次学习该实例，你可以直接将该实例丢弃（除非你想要将系统回退到之前的某个状态，并对数据进行重现）。这将节约大量的系统空间。</p>
<p>当训练数据量非常大时，也许我们设备的存储空间不能容纳下全部的训练数据，那么我们也可以使用在线学习算法（这也称为 <em>核外学习</em>）。算法只将部分的数据进行加载，先针对这些数据进行训练，之后重复这一过程，直到所有的数据都被训练过（见图 1-14）。</p>
<p><img src="./asset/1516713013659.png" alt="Alt text"><br>
<em>图 1-14 以在线学习的方式处理超大的数据集</em></p>
<p><img src="./asset/warning.png" alt="Alt text"><br>
<strong>特别注意：上述的所有过程通常是离线进行的（系统并不处于运行状态），所以 <em>在线学习</em> 这个名字总感觉令人困惑，你就认为它是 <em>增量式学习</em> 好了。</strong></p>
<p>在线学习系统中一个重要的参数是，在线学习应该以多快来适应新数据：这称为学习速率。如果你设置了一个高学习率，你的系统将能够快速适应新数据，但它也将很快 “忘记” 旧数据（你应该不会想要一个只能将与最新接收到的邮件类型相同的邮件标注出来的系统吧）。相反地，如果你设置了一个低学习率，系统将有更大的惯性，也就是说：它学得更慢，但同时对新数据中的噪声、非典型的数据点序列不敏感。</p>
<p>在线学习的一大挑战是：如果坏的数据被输入到系统中，系统的性能将会渐渐地下降。如果是在线运行的系统，这种变化将会被你的客户注意到。坏的数据可能来自于机器人上出故障的传感器，或者是某人对搜索引擎进行狂轰滥炸地输入某个搜索词以提高该词在搜索结果中的排名。为了减少这些风险，你需要密切监视你的系统，在你发现系统的性能下降时及时停止学习（如果可能的话，最好将系统回退到之前的某个工作状态）。你最好也能够对输入数据进行监视，剔除其中的异常数据（例如使用异常检测算法）。</p>
<h3 class="mume-header" id="%E5%9F%BA%E4%BA%8E%E5%AE%9E%E4%BE%8B-vs-%E5%9F%BA%E4%BA%8E%E6%A8%A1%E5%9E%8B">基于实例 VS 基于模型</h3>

<p>另一种区分机器学习系统的标准是根据问题——<strong>它们是怎么被构建起来的</strong> 确定的。绝大多数的机器学习任务都是关于预测的，这就意味着在给了一些训练数据进行训练之后，系统能够对它之前从未见过的实例进行归纳。对训练数据表现出不错的性能是很好，但这还不够，我们真正的目标是对新到来的实例能够有好的性能。</p>
<p>归纳的方式主要有两种：基于实例学习 和 基于模型学习。</p>
<h4 class="mume-header" id="%E5%9F%BA%E4%BA%8E%E5%AE%9E%E4%BE%8B%E5%AD%A6%E4%B9%A0">基于实例学习</h4>

<p>也许，最常见的学习方式是仅仅通过 “死记硬背” 的方式来学习。如果你构建的是这样的一个邮件过滤器，它将只能标记出那些与被用户标记过的邮件相同的邮件，不是最坏的模型，但绝对不会是最好的模型。</p>
<p>除了能够标记出与已知的垃圾文件完全相同的邮件外，你的邮件分类器还应该能够标记出与已知垃圾邮件非常相似的邮件。这就要求系统能够测试出两封邮件之间的相似度。一种非常基本的测试方案是计算两封邮件之间相同的单词的数量。如果新邮件中有大量的单词与已知垃圾邮件中的单词相同，就可以将该新邮件打上标记。</p>
<p>这就是 <em>基于实例的学习</em> ：系统记下所有的实例，之后用相似度对新的实例进行归纳（图 1-15）</p>
<p><img src="./asset/1516718784735.png" alt="Alt text"><br>
<em>图1-15 基于实例的学习</em></p>
<h4 class="mume-header" id="%E5%9F%BA%E4%BA%8E%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0">基于模型学习</h4>

<p>另一种方式是，从一个实例集中归纳出一般的规律，针对这些实例构建出一个模型，之后用这个模型进行预测，这就称为 <em>基于模型的学习</em>（图 1-16）<br>
<img src="./asset/1516719129963.png" alt="Alt text"><br>
<em>图 1-16 基于模型的学习</em></p>
<p>比方说你想要知道是否金钱真的能够使人开心，你可以从 <a href="https://goo.gl/0Eht9W">OECD's website</a> 上面下载 <em>生活幸福指数</em>，同时从 <a href="http://goo.gl/j1MSKe">IMF's websit</a> 下载对应国家的 <em>国内人均 GDP</em>。之后，你将这两个数据合并到同一个表中，并以人均GDP从高到底进行排列，表1-1 摘录了你所得到的表的一部分：</p>
<p><em>表 1-1 金钱真的使人更快乐吗？</em><br>
<img src="./asset/1516719585370.png" alt="Alt text"></p>
<p>让我们随机地取一部分数据以散点图的形式进行显示（图 1-17）：<br>
<img src="./asset/1516719680145.png" alt="Alt text"><br>
<em>图 1-17 你看到某种趋势了吗？</em></p>
<p>上图看起来确实有某种趋势。虽然数据有一些噪声（比如局部数据是随机分布的），不过整体上看，似乎人们的生活满意度随着各自国家人均GDP的上升而线性增长。所以，你决定建立一个生活满意度和人均GDP间呈线性函数关系的模型，这一步就成为 <em>模型选择</em>：你只选择人均GDP这一属性为生活满意度建立线性模型（等式 1-1）</p>
<p>        <em>等式 1-1. 一个简单的线性模型</em></p>
<p>        <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>l</mi><mi>i</mi><mi>f</mi><mi>e</mi><mi mathvariant="normal">_</mi><mi>s</mi><mi>a</mi><mi>t</mi><mi>i</mi><mi>s</mi><mi>f</mi><mi>a</mi><mi>c</mi><mi>a</mi><mi>t</mi><mi>i</mi><mi>o</mi><mi>n</mi><mo>=</mo><msub><mi>θ</mi><mn>0</mn></msub><mo>+</mo><msub><mi>θ</mi><mn>1</mn></msub><mo>×</mo><mi>G</mi><mi>D</mi><mi>P</mi><mi mathvariant="normal">_</mi><mi>p</mi><mi>e</mi><mi>r</mi><mi mathvariant="normal">_</mi><mi>c</mi><mi>a</mi><mi>p</mi><mi>i</mi><mi>t</mi><mi>a</mi></mrow><annotation encoding="application/x-tex">life\_satisfacation=\theta_0+\theta_1\times GDP\_per\_capita</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.69444em;"></span><span class="strut bottom" style="height:1.00444em;vertical-align:-0.31em;"></span><span class="base"><span class="mord mathit" style="margin-right:0.01968em;">l</span><span class="mord mathit">i</span><span class="mord mathit" style="margin-right:0.10764em;">f</span><span class="mord mathit">e</span><span class="mord mathrm" style="margin-right:0.02778em;">_</span><span class="mord mathit">s</span><span class="mord mathit">a</span><span class="mord mathit">t</span><span class="mord mathit">i</span><span class="mord mathit">s</span><span class="mord mathit" style="margin-right:0.10764em;">f</span><span class="mord mathit">a</span><span class="mord mathit">c</span><span class="mord mathit">a</span><span class="mord mathit">t</span><span class="mord mathit">i</span><span class="mord mathit">o</span><span class="mord mathit">n</span><span class="mrel">=</span><span class="mord"><span class="mord mathit" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathrm mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"></span></span></span></span></span><span class="mbin">+</span><span class="mord"><span class="mord mathit" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathrm mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"></span></span></span></span></span><span class="mbin">×</span><span class="mord mathit">G</span><span class="mord mathit" style="margin-right:0.02778em;">D</span><span class="mord mathit" style="margin-right:0.13889em;">P</span><span class="mord mathrm" style="margin-right:0.02778em;">_</span><span class="mord mathit">p</span><span class="mord mathit">e</span><span class="mord mathit" style="margin-right:0.02778em;">r</span><span class="mord mathrm" style="margin-right:0.02778em;">_</span><span class="mord mathit">c</span><span class="mord mathit">a</span><span class="mord mathit">p</span><span class="mord mathit">i</span><span class="mord mathit">t</span><span class="mord mathit">a</span></span></span></span></p>
<p>这个模型有两个模型参数，<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>θ</mi><mn>0</mn></msub></mrow><annotation encoding="application/x-tex">\theta_0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.69444em;"></span><span class="strut bottom" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="base"><span class="mord"><span class="mord mathit" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathrm mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"></span></span></span></span></span></span></span></span> 和 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>θ</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">\theta_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.69444em;"></span><span class="strut bottom" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="base"><span class="mord"><span class="mord mathit" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathrm mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"></span></span></span></span></span></span></span></span>。通过调整这些参数，你可以得到任何你想表示的线性函数，如图 1-18 所示。<br>
<img src="./asset/1516760088927.png" alt="Alt text"><br>
<em>图 1-18 若干可能的线性模型</em></p>
<p>在你使用你的模型前，必须先确定参数 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>θ</mi><mn>0</mn></msub></mrow><annotation encoding="application/x-tex">\theta_0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.69444em;"></span><span class="strut bottom" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="base"><span class="mord"><span class="mord mathit" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathrm mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"></span></span></span></span></span></span></span></span> 和 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>θ</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">\theta_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.69444em;"></span><span class="strut bottom" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="base"><span class="mord"><span class="mord mathit" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathrm mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"></span></span></span></span></span></span></span></span> 的值。那你确定你所取得参数值能够使模型的性能最好呢？为了回答这个问题，你需要先明确性能测量的方式。你既可以定义一个 <em>效用函数</em>（或称为 <em>适配函数</em>）来测量你的模型有多好，也可以定义一个 <em>代价函数</em> 来测量你的模型有差。就线性回归问题而言，通常使用线性模型的预测值和训练样本的实际值之间的欧式距离作为代价函数。训练的目标就是最小化这个距离。</p>
<p>线性回归算法的工作原理是：你将训练数据交给它，它负责找出一组模型的参数，这组参数能够使你的线性模型与数据吻合得最好，这个过程就称为 <em>训练</em>模型。在我们这个例子中，算法发现最佳的参数值是 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>θ</mi><mn>0</mn></msub><mo>=</mo><mn>4</mn><mi mathvariant="normal">.</mi><mn>8</mn><mn>5</mn></mrow><annotation encoding="application/x-tex">\theta_0=4.85</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.69444em;"></span><span class="strut bottom" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="base"><span class="mord"><span class="mord mathit" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathrm mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"></span></span></span></span></span><span class="mrel">=</span><span class="mord mathrm">4</span><span class="mord mathrm">.</span><span class="mord mathrm">8</span><span class="mord mathrm">5</span></span></span></span>，<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>θ</mi><mn>1</mn></msub><mo>=</mo><mn>4</mn><mi mathvariant="normal">.</mi><mn>9</mn><mn>1</mn><mo>×</mo><mn>1</mn><msup><mn>0</mn><mrow><mo>−</mo><mn>5</mn></mrow></msup></mrow><annotation encoding="application/x-tex">\theta_1=4.91\times10^{-5}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.8141079999999999em;"></span><span class="strut bottom" style="height:0.964108em;vertical-align:-0.15em;"></span><span class="base"><span class="mord"><span class="mord mathit" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathrm mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"></span></span></span></span></span><span class="mrel">=</span><span class="mord mathrm">4</span><span class="mord mathrm">.</span><span class="mord mathrm">9</span><span class="mord mathrm">1</span><span class="mbin">×</span><span class="mord mathrm">1</span><span class="mord"><span class="mord mathrm">0</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">−</span><span class="mord mathrm mtight">5</span></span></span></span></span></span></span></span></span></span></span></span>。</p>
<p>现在，这个模型与训练数据吻合得最好（对线性模型而言），如图 1-19所示：<br>
<img src="./asset/1516761258332.png" alt="Alt text"><br>
<em>图 1-19 与给定数据最吻合的线性模型</em></p>
<p>你可以使用该模型进行数据预测了：你想要知道塞浦路斯人的幸福指数，但在 OECD网站上并没有给出答案。幸运的是，你可以使用你训练好的模型进行预测：先获取塞浦路斯的人均GDP，为 22587美元 ，将这个值代入你的模型就可以得到他们的生活满意度应该大致为 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mn>4</mn><mi mathvariant="normal">.</mi><mn>8</mn><mn>5</mn><mo>+</mo><mn>2</mn><mn>2</mn><mn>5</mn><mn>8</mn><mn>7</mn><mo>×</mo><mn>4</mn><mi mathvariant="normal">.</mi><mn>9</mn><mn>1</mn><mo>×</mo><mn>1</mn><msup><mn>0</mn><mrow><mo>−</mo><mn>5</mn></mrow></msup><mo>=</mo><mn>5</mn><mi mathvariant="normal">.</mi><mn>9</mn><mn>6</mn></mrow><annotation encoding="application/x-tex">4.85+22587\times4.91\times10^{-5}=5.96</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.8141079999999999em;"></span><span class="strut bottom" style="height:0.897438em;vertical-align:-0.08333em;"></span><span class="base"><span class="mord mathrm">4</span><span class="mord mathrm">.</span><span class="mord mathrm">8</span><span class="mord mathrm">5</span><span class="mbin">+</span><span class="mord mathrm">2</span><span class="mord mathrm">2</span><span class="mord mathrm">5</span><span class="mord mathrm">8</span><span class="mord mathrm">7</span><span class="mbin">×</span><span class="mord mathrm">4</span><span class="mord mathrm">.</span><span class="mord mathrm">9</span><span class="mord mathrm">1</span><span class="mbin">×</span><span class="mord mathrm">1</span><span class="mord"><span class="mord mathrm">0</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">−</span><span class="mord mathrm mtight">5</span></span></span></span></span></span></span></span></span><span class="mrel">=</span><span class="mord mathrm">5</span><span class="mord mathrm">.</span><span class="mord mathrm">9</span><span class="mord mathrm">6</span></span></span></span> 。</p>
<p>为了满足你的好奇心，例1-1 中的Python代码实现了数据的加载，预处理，将数据以散点图的形式进行可视化，之后进行线性模型的训练，最后将完成训练的模型用于预测。</p>
<blockquote>
<p>注：如果你不理解其中的代码也没有关系，在接下来的章节我们就会介绍Scikit-Learn库。</p>
</blockquote>
<p><em>例 1-1. 用Scikit-Learn训练并运行一个线性模型</em></p>
<pre class="language-python"><span class="token keyword">import</span> matplotlib
<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd
<span class="token keyword">from</span> sklearn <span class="token keyword">import</span> linear_model
<span class="token keyword">from</span> sklearn <span class="token keyword">import</span> neighbors

<span class="token comment" spellcheck="true"># 数据加载</span>
oecd_bli <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span><span class="token string">"oecd_bli_2015.csv"</span><span class="token punctuation">,</span> thousands<span class="token operator">=</span><span class="token string">","</span><span class="token punctuation">)</span>
gdp_per_capita <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span><span class="token string">"gdp_per_capita.csv"</span><span class="token punctuation">,</span> thousands<span class="token operator">=</span><span class="token string">","</span><span class="token punctuation">,</span>
    delimiter<span class="token operator">=</span><span class="token string">"\t"</span><span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">'latin1'</span><span class="token punctuation">,</span> na_values<span class="token operator">=</span><span class="token string">"n/a"</span><span class="token punctuation">)</span>
<span class="token comment" spellcheck="true"># 数据的预处理 假定函数 perpare_country_stats已经完成定义</span>
<span class="token comment" spellcheck="true"># 用于将 GDP和生活满意度合并到同一个Pandas dataframe</span>
country_stats <span class="token operator">=</span> prepare_country_stats<span class="token punctuation">(</span>oecd_bli<span class="token punctuation">,</span> gdp_per_capita<span class="token punctuation">)</span>
X <span class="token operator">=</span> np<span class="token punctuation">.</span>c_<span class="token punctuation">[</span>country_stats<span class="token punctuation">[</span><span class="token string">"GDP per capita"</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
y <span class="token operator">=</span> np<span class="token punctuation">.</span>c_<span class="token punctuation">[</span>country_stats<span class="token punctuation">[</span><span class="token string">"Life satisfaction"</span><span class="token punctuation">]</span><span class="token punctuation">]</span>

<span class="token comment" spellcheck="true"># 数据的可视化</span>
country_stats<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>kind<span class="token operator">=</span><span class="token string">"scatter"</span><span class="token punctuation">,</span> x<span class="token operator">=</span><span class="token string">"GDP per capita"</span><span class="token punctuation">,</span>
    y<span class="token operator">=</span><span class="token string">"Life satisfaction"</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># 选择一个线性模型</span>
clf <span class="token operator">=</span> linear_model<span class="token punctuation">.</span>LinearRegression<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># 训练模型</span>
clf<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>X<span class="token punctuation">,</span> y<span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># 对塞浦路斯进行预测</span>
X_new <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">22587</span><span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token comment" spellcheck="true"># 塞浦路斯的人均GDP</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>clf<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>X_new<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># 输出为 [[ 5.96242338]]</span>
</pre>
<p><img src="./asset/note.png" alt="Alt text"><br>
如果你使用基于实例的学习算法就会发现，斯洛文尼亚和塞浦路斯的人均GDP最接近，而斯洛文尼亚在OECD上显示的生活幸福指数是5.7，因此，你的算法也许会预测塞浦路斯的生活幸福指数也是5.7。如果你把观察的范围扩大到最接近的3个国家，你将发现葡萄牙和西班牙的幸福指数分别为5.1 和 6.5。求这3个国家的幸福指数的平均值，可以得到5.77，已经非常接近使用基于模型算法得到的预测值。这种简单的算法被称为 <em>k-近邻</em> 回归（在这个例子中，k=3）。<br>
如果用k-近邻实现代码也非常简单，只需要将之前的代码：<br>
<code>clf = linear_model.LinearRegression()</code><br>
替换为：<br>
<code>clf = neighbors.KNeighborsRegressor(n_neighbors=3)</code><br>
即可。</p>
<p>如果顺利的话，你的模型可以做出很好的预测。否则，你可能需要更多的属性（如就业率、健康、空气污染等），也可以是选择更多或质量更好的训练数据，或者是更加强大的模型（比如说是多项式回归模型）。</p>
<p>总结来说：</p>
<ul>
<li>你需要数据进行分析</li>
<li>你需要选择一个学习模型</li>
<li>你需要使用训练数据对其进行训练（比如说，学习算法需要找到使代价函数最小的一组模型参数）</li>
<li>最后，你将这个训练好的模型应用到对新实例的预测中（这个过程称为推断），并期望得到好的结果</li>
</ul>
<p>这就是典型的基于模型学习算法的工作流程。在第二章中，通过实践一个端到端的项目，你将会有更加直接的体验。</p>
<p>到目前为止，我们介绍了很多的机器学习分类，你应该找到了：机器学习到底是什么？它为什么非常有用？机器学习系统最常见的分类有哪些？典型的项目工作流程是怎样的？那么，让我们看看哪些因素会导致训练失败，预测结果不准确。</p>
<h3 class="mume-header" id="%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E4%B8%BB%E8%A6%81%E6%8C%91%E6%88%98">机器学习的主要挑战</h3>

<p>简而言之，你的主要工作是选择一个学习算法和将数据给这个算法训练，因此训练失败的元素也分为两类：“选了不合适的算法” 和 “数据不好”。让我们先来看看坏数据的一个例子。</p>
<h4 class="mume-header" id="%E8%AE%AD%E7%BB%83%E6%95%B0%E6%8D%AE%E4%B8%8D%E5%85%85%E8%B6%B3">训练数据不充足</h4>

<p>对于一个三岁小孩来说，要让他认识什么是苹果，只需要手指指着一个苹果说 “苹果” 就可以了（也许需要多次重复这个过程）。之后，小孩就能分辨出任何颜色、任何形状的苹果了。真是天才！</p>
<p>机器学习就不是这样了，几乎所有的机器学习要能正常工作都需要大量的数据。即使是非常简单的问题，你也需要提供上千个实例，而对于复杂的问题，如图像或语音识别，你可能需要上百万个实例（除非你能找到一个已经存在的，和你问题相似的模型）。</p>
<h5 class="mume-header" id="%E6%95%B0%E6%8D%AE%E4%B8%8D%E5%8F%AF%E6%80%9D%E8%AE%AE%E7%9A%84%E8%83%BD%E5%8A%9B">数据不可思议的能力</h5>

<p>2001年，微软的研究员Michele Banko 和 Eric Brill 发表了一篇著名的论文，在这篇论文中展示了一些非比寻常的机器学习算法，其中包括一个非常简单，只需要足够的数据量，就能解决复杂的自然语言歧义问题（例如：是单词“to”，还是“two”，还是“too” 需要根据上下文确定），如图 1-20所示：<br>
<img src="./asset/1516780410208.png" alt="Alt text"><br>
<em>图 1-20 数据和算法的重要性</em></p>
<p>作者提出：这些结果让我们重新思考，是应该花大量的时间和金钱来改进发展算法还是将这些时间和金钱用于语料库的开发。</p>
<p>2009年，Peter Norvig 等人发表了一篇标题为 《数据不可思议的有效性》的论文，他们都认为对于复杂的问题而言，数据远比算法来的重要。但需要注意的是，小型或者中型的数据集仍然非常普遍，而且并不总是能够简单地获得额外的训练数据，所以，抛弃算法还为时过早。</p>
<h4 class="mume-header" id="%E9%9D%9E%E5%85%B8%E5%9E%8B%E8%AE%AD%E7%BB%83%E6%95%B0%E6%8D%AE">非典型训练数据</h4>

<p>为了得到较好的泛化性能（预测结果），你的训练数据对你想要预测的实例具有代表性就显得非常重要，这不管是对基于模型的训练还是基于实例的训练都成立。</p>
<p>比如说之前预测满意度的那个例子，如果我们使用的数据集并不是具有代表性的（之前我们把一些国家的数据去掉了，现在把它们补回来），散点图如 1-21：<br>
<img src="./asset/1516781831639.png" alt="Alt text"><br>
<em>图 1-21 一个更具有代表性的训练数据样本</em></p>
<p>如果你使用这些数据进行训练，你将得到一个如实线所示的函数模型。如果你用先前的数据进行训练，得到的模型如图中虚线所示。正如你所见，，增加几个点不仅仅是改变了训练模型，而且也意味着这种简单的线性模型可能改变就不适合用于解决该问题。可以看到，非常富裕国家的人民不会比中等富裕国家的人民更快乐（实际上看起来更不快乐），相反的，一些贫穷国家的人民看起来比富裕国家的人民更快乐。</p>
<p>通过使用一组非典型的训练集，我们所训练的模型不太可能在应用时做出准确的预测，特别是当我们的训练集是非常穷或非常富的国家时。</p>
<p>选取的训练集相对于你要预测的实例来说是典型的，这一点非常重要。但真正做到这一点并没有它听起来的那么简单，如果采样的样本太小，你的采样中会存在大量的噪声（例如：非典型样本就是一种可能），但即使是非常大的样本，如果采样方式存在缺陷，也会导致采集到的数据是非典型的，这称为采样偏差。</p>
<h4 class="mume-header" id="%E4%B8%80%E4%B8%AA%E8%91%97%E5%90%8D%E7%9A%84%E9%87%87%E6%A0%B7%E5%81%8F%E5%B7%AE%E7%9A%84%E4%BE%8B%E5%AD%90">一个著名的采样偏差的例子</h4>

<p>也许，最著名的采样偏差的例子发生在1936年美国总统的竞选期间，竞选双方分别是罗斯福和兰登，<em>文学文摘</em> 做了一个非常大型的民意调查，它发送了大约1000万份的问卷调查，其中收到240万份回答，之后，它高度自信的预测兰登将会得到57%的选票。但事实是，罗斯福得到62%的选票。问题出在 <em>文学文摘</em> 的采样方式上：</p>
<ul>
<li>首先，为了发送问卷调查，他们从杂志订阅名单、俱乐部成员名单和其他相似的途径获得通信地址。这些名单上面的通常是较为富裕的人，他们更倾向于把选票投给共和党（也就是兰登）</li>
<li>其次，收到的回复少于25%，这也是一种采样偏差，排除了那些不关心政治、或者不喜欢 <em>文学文摘</em>，以及其他的一些人。这种特别的采样偏差也称为 <em>无回复偏差</em>。</li>
</ul>
<p>还有一个例子，比如你打算建立一个系统来识别 <em>放克音乐</em>。一种建立训练集的方式是：在YouTube上搜索 “放克音乐” 关键字，并将搜索结果作为训练集。但是，这种方式的一个前提假定是，YouTube搜索引擎所列出的音乐都是典型的放克音乐。实际上，搜索结果是偏向于流行音乐的类型的（如果你生活在巴西，你会听到很多 “funk carioca” 的音乐，这些听起来与 布朗.詹姆斯 的完全不同）。那么，我们应该如何获取大量的训练数据集呢？</p>
<h3 class="mume-header" id="%E4%BD%8E%E8%B4%A8%E9%87%8F%E7%9A%84%E6%95%B0%E6%8D%AE">低质量的数据</h3>

<p>显然，如果你的训练数据中充满了错误的、异常的、有噪声的（比如说测量水平低），那对系统来说发现其中潜在的规律/模式就非常困难，那也就不要指望你的系统能够有好的性能，因此，花时间和精力来进行数据清理通常都是非常必要的。实际情况就是：大多数的数据科学家将他们大部分的时间花费在数据清理上面，比如说：</p>
<ul>
<li>如果在训练集中存在明显的异常值，只需要简单地忽略它们或者是手动修改它们的值。</li>
<li>如果某些实例缺少一个或多个属性（例如：5% 的顾客没有提供他们的年龄信息），你要么选择忽略这些属性，要么选择忽略这些实例，或者是将这些缺失的属性补上（比如可以用平均年龄来替代），或者是一个模型使用这些属性，而另一个模型不使用这些属性，等等。</li>
</ul>
<h3 class="mume-header" id="%E6%97%A0%E5%85%B3%E7%89%B9%E5%BE%81">无关特征</h3>

<p>正所谓，废料进，废品出（garbage in,garbage out）。只有在你的训练数据中有足够的相关特征和不是太多的无关特征，你的系统才能被训练。成功实现机器学习项目的关键要素之一是提取出好的特征进行训练。这个过程我们称之为 <em>特征工程</em>，包括：</p>
<ul>
<li>特征选择：从现有的所有特征中选择最有用的特征用于训练</li>
<li>特征提取：将多个特征组合在一起形成一个更有用的特征（例如之前所说的数据降维）</li>
<li>通过收集新数据，创建新特征</li>
</ul>
<p>到目前为止，我们见识了很多“坏数据”的例子，接下来让我们看看什么是“坏算法”。</p>
<h3 class="mume-header" id="%E8%AE%AD%E7%BB%83%E6%95%B0%E6%8D%AE%E7%9A%84%E8%BF%87%E6%8B%9F%E5%90%88">训练数据的过拟合</h3>

<p>如果你去国外的某个国家旅游，不幸地被出租车司机打劫。你也许会说这个国家的所有出租车司机都是强盗。偏激地妄下结论是我们人类经常干的事，而一不小心，机器学习也会掉入这个陷阱中，称为 <em>过拟合</em>，表示模型在训练数据集上表现得很好，但它对于新数据不具备好的性能。</p>
<p>图 1-22 展示了一个高次多项式模型对训练数据的过拟合。即使它对训练数据的性能表现得比简单线性模型要好，，但你是否真的相信它对新数据的预测结果？</p>
<p><img src="./asset/Figure1-22.png" alt="Figure 1-22"><br>
<em>图 1-22. 对训练数据的过拟合</em></p>
<p>像深度神经网络这种复杂的模型能够发现数据中微小的规律(模式)，但如果训练数据中有很多的噪声，或者数据规模太小（这也就引入了采样噪声），那么模型就会把噪声也当做一种“规律”。当然，这些 “规律” 不会有助于对新实例的预测。比如说，你给预测生活满意度的那个模型提供了更多的属性，也包括对训练来说无意义的属性，例如国家的名称，在这种情况下，一个复杂的模型可能会得出下列荒诞的结论：所有名字中有 'w' 的国家，幸福指数都大于7，比如说新西兰(New Zealand)的7.3，挪威(Norway)的7.4，瑞典(Sweden)的7.2，瑞士(Switzerland)的7.5。那你有多少信心说这个 “W-满意理论” 同样适用于卢旺达(Rwanda) 和 津巴布韦(Zimbabwe)？显然，在训练数据中这种所谓的规律纯属巧合，但是模型不能分辨出哪些规律是真实存在的，哪些仅仅是巧合。</p>
<p><img src="asset/warning.png" alt="Warning">过拟合主要发生在相对于训练数据量和噪声，模型太过复杂的情况下。解决方案可以是：</p>
<ul>
<li>通过选择参数更少的模型来对训练模型进行简化（比如选择一个线性模型而不是高次多项式模型），减少特征属性的数量或者对模型进行约束</li>
<li>获取更多的训练数据</li>
<li>减少训练数据中的噪声（修正错误的数据，删除异常数据）</li>
</ul>
<p>约束模型的复杂度以避免过拟合称为 <strong>正规化</strong>。比如说，之前的线性模型中我们定义了两个参数 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>θ</mi><mn>0</mn></msub></mrow><annotation encoding="application/x-tex">\theta_0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.69444em;"></span><span class="strut bottom" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="base"><span class="mord"><span class="mord mathit" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathrm mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"></span></span></span></span></span></span></span></span> 和 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>θ</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">\theta_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.69444em;"></span><span class="strut bottom" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="base"><span class="mord"><span class="mord mathit" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathrm mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"></span></span></span></span></span></span></span></span>。这使得学习算法有两个自由度来调节模型逼近训练数据：它能够调整直线的高度(<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>θ</mi><mn>0</mn></msub></mrow><annotation encoding="application/x-tex">\theta_0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.69444em;"></span><span class="strut bottom" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="base"><span class="mord"><span class="mord mathit" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathrm mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"></span></span></span></span></span></span></span></span>) 或者是斜率(<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>θ</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">\theta_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.69444em;"></span><span class="strut bottom" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="base"><span class="mord"><span class="mord mathit" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathrm mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"></span></span></span></span></span></span></span></span>)。如果我们强制<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>θ</mi><mn>1</mn></msub><mo>=</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">\theta_1=0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.69444em;"></span><span class="strut bottom" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="base"><span class="mord"><span class="mord mathit" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathrm mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"></span></span></span></span></span><span class="mrel">=</span><span class="mord mathrm">0</span></span></span></span>,学习算法可调节的自由度只有1，这使得要让模型匹配训练数据变得非常困难：它只能将直线进行上下移动，尽量使之靠近训练数据，最终的结果是直线停在训练数据的均值附近。确实是非常简单的模型！而如果我们允许学习算法调节<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>θ</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">\theta_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.69444em;"></span><span class="strut bottom" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="base"><span class="mord"><span class="mord mathit" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathrm mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"></span></span></span></span></span></span></span></span>，要求是<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>θ</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">\theta_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.69444em;"></span><span class="strut bottom" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="base"><span class="mord"><span class="mord mathit" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathrm mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"></span></span></span></span></span></span></span></span>必须取较小，则实际上，学习算法的自由度在1~2之间，它将产生一个比2自由度更简单的，但比1自由度更复杂的模型。你需要在保持对训练数据匹配的同时，使训练模型足够简单，以确保其具有较好的泛化能力。</p>
<p>图 1-23 展示了3种模型：虚线表示只使用部分国家进行训练的第一个的模型，短画线表示用所有国家进行训练的第二个模型，实线表示使用与第一个模型相同的训练数据，但是有正规化约束所训练出来的模型。从图中可以看出，常用正规化约束得到的模型具有较小的斜率，虽然对训练数据(蓝色点)的匹配程度不如普通模型(虚线)，但是对新案例(红色点)的预测效果更好。</p>
<p><img src="./asset/Figure1-23.png" alt="Figure 1-23"><br>
<em>图 1-23 正规化降低了过拟合的风险</em></p>
<p>这些在训练过程中的应用的正规化行为，可以通过一个 <em>超参数</em> 进行控制。一个超参数是学习算法的一个参数(注意：不是模型的参数)，因此，学习算法训练的过程中并不会改变这个超参数的值，它必须在训练开始前就设置好。如果你将超参数设置得非常大，你得到的将是“平”的一条线（斜率几乎等于0）；学习算法几乎可以肯定不会发生过拟合现象，但也绝不会是一个好的模型。调节超参数是建立机器学习系统中非常重要的部分（你将会在下一章中看到具体的例子）。</p>
<h3 class="mume-header" id="%E8%AE%AD%E7%BB%83%E6%95%B0%E6%8D%AE%E7%9A%84%E6%AC%A0%E6%8B%9F%E5%90%88">训练数据的欠拟合</h3>

<p>如你所料，<em>欠拟合</em> 正好与过拟合相反：当你的模型太过简单，没有能力表现数据中潜在的规律，欠拟合就发生了。比如说，生活幸福指数的线性模型就有些欠拟合，实际上，只需要模型复杂一点，它在训练集和预测上的结果就会更加精确。</p>
<p>解决欠拟合问题的思路：</p>
<ul>
<li>选择一个有更多参数的更强大的模型</li>
<li>选择更好的特征用于学习算法（特征工程）</li>
<li>降低对模型的约束（例如减小正规化的超参数）</li>
</ul>
<h3 class="mume-header" id="%E5%9B%9E%E9%A1%BE">回顾</h3>

<p>到目前为止，你已经对机器学习有了一些了解。其中的概念有很多，其中一些你可能有点忘记了，让我们对之前的内容来一个整体的回归：</p>
<ul>
<li>机器学习是通过对数据的学习使得机器(也可以是一个程序)对某些任务来说有更好的性能，而不是对这些任务进行手动地编码。</li>
<li>存在很多种机器学习系统：监督的和非监督的，批量的和在线的，基于实例的和基于模型的 等等。</li>
<li>在机器学习项目中，你将数据组成一个训练集，并将训练集提供给学习算法。如果算法是基于模型的，学习算法就会通过调节模型中的参数使模型逼近于训练数据（例如，对训练集自身能够有好的预测结果），那么这个模型很可能对新实例也有好的预测结果。如果算法是基于实例的，学习算法只是将所有训练集中的数据记录下来，当新数据到来时，通过相似度测量的方法对其进行预测。</li>
<li>如果你的训练集太小，或者训练数据不具有代表性，或者包含很多噪声，或者被非相关的特征所污染(废料进、废品出)，你的系统将不会得到好的性能。最后，你的模型及不能太简单(会引起欠拟合)，也不能太复杂(会引起过拟合)。</li>
</ul>
<p>还有最后一个重要的话题：如果你完成了一个模型的训练，你不会只是希望将它应用于对新数据的预测中。你想要评估这个模型的好坏，如果必要的话，对它进行调整。让我们看看这一步怎么完成。</p>
<h3 class="mume-header" id="%E6%B5%8B%E8%AF%95%E5%92%8C%E9%AA%8C%E8%AF%81">测试和验证</h3>

<p>想要知道一个模型好坏的唯一方式是用它对新实例进行测试。一种方式是将你的模型放在生产环境中，观察它表现的如何。这种方式能过对模型进行评估，但是如果你的模型非常糟糕，用户将会抱怨--不是最好的途径。</p>
<p>一个更好的选择是：将你的数据分成两个部分，<em>训练集</em> 和 <em>测试集</em>，顾名思义，你使用训练集对你的模型进行训练，用测试集测试训练后模型的好坏。在新数据上的错误率称为<em>泛化误差</em>（或者称为<em>样本外误差</em>），将测试集用于对模型的评估，你可以估计泛化误差。这个值告诉你，对于一个从来没有见过的实例，你的模型会表现得怎么样。</p>
<p>如果训练误差小（比如说，你的模型对训练数据很少产生错误），但是泛化误差很大，这表示你的模型已经过拟合了。</p>
<p><img src="./asset/suggest.png" alt="suggest">通常来说，取 “训练数据 : 测试数据 = 8 : 2”</p>
<p>对模型的评估也就变得足够简单：一个测试集就够了。假如你正在纠结于两个模型之间（比如说一个是线性模型，另一个是多项式模型），你该如何做决定？一种方法是对这两个模型都进行训练，最后通过测试集评估它们的泛化能力。</p>
<p>假设线性模型的泛化性能更好，而你想要设置某些正规化规则以避免过拟合。问题是：你应该如何选择用于正规化的超参数？一种方法是你用100个不同的值作为超参数，训练出100个不同的模型，假定你找到的最好的超参数能够使模型的泛化误差只有5%，你将这个模型应用到生产中，但不幸地是，在生产中你模型的泛化误差可能达到了15%，这又是为什么呢？</p>
<p>问题在于，你测量泛化误差时使用的都是同一个测试集，因此，你所选出来的最好的模型、超参数都是针对测试集而言最好的，这也就意味着，针对新数据而言，模型不会表现得同样好。</p>
<p>一个常用的解决方案是，再从数据中划分出一部分数据，作为 <em>确认集</em>。你用很多的超参数训练出很多模型，之后选出一个在确认集上泛化性能最好的模型及其超参数，最后将这个模型通过测试集进行一次测试，如果得到了令人满意的泛化误差，训练才算完成。</p>
<p>为了避免 “浪费” 过多的训练数据用于确认集，一种通用的技术是 <em>交叉验证</em>：将训练集分成互斥的多个子集，通过随机选择部分子集进行组合对不同模型进行训练，通过用剩余部分子集对模型进行确认。在模型类型和超参数确定以后，最终的模型使用使用这些超参数以及整个训练集进行训练，而泛化误差通过测试集进行测算。</p>
<h4 class="mume-header" id="%E6%B2%A1%E6%9C%89%E5%85%8D%E8%B4%B9%E5%8D%88%E9%A4%90%E7%90%86%E8%AE%BA">没有免费午餐理论</h4>

<p>一个模型是观测结果一个简化版本。简化版本就意味着忽略那些对在新实例上泛化没有帮助的多余细节。但是，要决定什么数据需要保持，什么数据需要忽略，你必须先做出一个假定。比如说，选择一个线性模型就表示做了一个假定：数据基本上是线性的，而实例与实线的距离是由噪声引起的，这些距离可以忽略。</p>
<p>在1996年一篇著名的论文中（“The Lack of A Priori Distinctions Between Learning Algorithm”），David Wolpert证明了，在对数据没有任何假定的情况下，没有理由认为某个模型好于另一个,这一理论称为 <em>没有免费午餐</em>(No Free Lunch,NFL)理论。对于某些数据集而言，线性模型最合适，而对于另一些数据集，可能神经网络更合适。谁也不能预测哪个模型可以工作得更好，确定哪个模型最好的唯一方式是对所有模型都进行评估，显然这是不可能的，在实际中，你会对给定的数据做出一些合理的假设，然后选出你认为合理的模型。比如说，对于一个简单的任务，你可能会选择线性模型和多种方式的正规化，而对于一个复杂问题，你也许会选择多种神经网络模型。</p>
<h3 class="mume-header" id="%E7%BB%83%E4%B9%A0">练习</h3>

<p>在本章中，我们介绍了机器学习中一些最重要的概念。下一章节，我们将会更深入，编写更多的代码。但在开始之前，你先确定下面的问题你都能回答了：</p>
<ol>
<li>你怎么定义机器学习？</li>
<li>你能说出可以运用机器学习解决的4种问题吗？</li>
<li>被标记了的训练集是什么意思？</li>
<li>两种最常见的监督学习任务是什么？</li>
<li>你能说出哪些最常见的非监督学习的算法？</li>
<li>使用哪种机器学习算法能够让一个机器人在复杂的环境中行走？</li>
<li>什么算法能将你的顾客分成多个组？</li>
<li>你能将垃圾邮件检测问题构造成一个监督学习问题或非监督学习问题吗？</li>
<li>什么是在线学习系统？</li>
<li>什么是核外学习？</li>
<li>哪种类型的学习算法基于相似度测量来做出预测？</li>
<li>请说出模型参数和学习算法超参数的区别？</li>
<li>在基于模型的学习算法中，训练过程中求的是什么？求解这些量通常使用什么方法？训练出的模型如何做预测？</li>
<li>你能说出机器学习所面临的4种主要挑战吗？</li>
<li>如果你的模型在训练集上有很好的性能，而在新实例上的预测效果却不理想，为什么会出现这种情况？你能说出3中可能的解决方案吗？</li>
<li>什么是测试集？为什么你要使用它？</li>
<li>确认集干什么用的？</li>
<li>如果你用测试集调整超参数会有什么问题？</li>
<li>什么是交叉验证？为什么要将用它创建确认集？</li>
</ol>
<p>答案见附录A。</p>
<h2 class="mume-header" id="%E7%AC%AC%E4%BA%8C%E7%AB%A0-%E4%BB%8E%E5%A4%B4%E5%88%B0%E5%B0%BE%E5%AE%9E%E8%B7%B5%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E9%A1%B9%E7%9B%AE">第二章 从头到尾实践机器学习项目</h2>

<p>在这一章中，假设你被一个房地产公司录用当一名数据科学家，你将完成一个完整的机器学习项目。下面是你将要做的主要内容：</p>
<ol>
<li>观察一幅大的图片</li>
<li>获得数据</li>
<li>将数据可视化，并获得某些直觉上的认识</li>
<li>为机器学习算法准备数据</li>
<li>选择一个模型进行训练</li>
<li>对你的模型进行调优</li>
<li>给出你的解决方案</li>
<li>载入，监视和维护你的系统</li>
</ol>
<blockquote>
<p>注：这个例子完全是虚构的，只是为了向你讲解机器学习项目所需要的主要步骤，而不是学习什么关于房地产交易。</p>
</blockquote>
<h3 class="mume-header" id="%E5%B7%A5%E4%BD%9C%E5%9C%A8%E7%9C%9F%E5%AE%9E%E7%9A%84%E6%95%B0%E6%8D%AE%E4%B9%8B%E4%B8%8A">工作在真实的数据之上</h3>

<p>当你在学机器学习时，最好是拿真实世界的数据进行试验，而不是人为制造的。幸运的是，有包含各个领域的上千个开放数据集可供选择。下面是一些你可以获得数据资源的地方：</p>
<ul>
<li>流行的开放数据仓库
<ul>
<li><a href="http://archive.ics.uci.edu/ml/index.php">UC Irvine Machine Learning Repository</a></li>
<li><a href="https://www.kaggle.com/datasets">Kaggle datasets</a></li>
<li><a href="https://aws.amazon.com/fr/datasets/">Amazon's AWS datasets</a></li>
</ul>
</li>
<li>元门户网站（它们给出了开放数据仓库列表）
<ul>
<li><a href="http://dataportals.org">http://dataportals.org</a></li>
<li><a href="http://opendatamonitor.eu/">http://opendatamonitor.eu/</a></li>
<li><a href="http://quandl.com/">http://quandl.com/</a></li>
</ul>
</li>
<li>其他的列出很多流行、开放数据仓库的网站
<ul>
<li><a href="https://en.wikipedia.org/wiki/List_of_datasets_for_machine_learning_research">Wikipedia's list of Machine Learning datasets</a></li>
<li><a href="https://www.quora.com/Where-can-I-find-large-datasets-open-to-the-public">Quora.com question</a></li>
<li><a href="https://www.reddit.com/r/datasets/">Datasets subreddit</a></li>
</ul>
</li>
</ul>
<h1 class="mume-header" id="%E9%99%84%E5%BD%95a-%E7%BB%83%E4%B9%A0%E7%9A%84%E7%AD%94%E6%A1%88">附录A 练习的答案</h1>

<h2 class="mume-header" id="%E7%AC%AC%E4%B8%80%E7%AB%A0-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%BA%B5%E8%A7%88-1">第一章 机器学习纵览</h2>

<ol>
<li>机器学习是建立一个能够从数据中进行学习的系统。学习的意思是让机器能够获得更好的性能。</li>
<li>目前来说没有算法可以解决的复杂问题；需要手动编写并维护大量规则的问题；需要能够根据环境变化及时作出调整的问题；辅助人类进行学习；</li>
<li>一个被标记了的训练集是指每一个实例都包含正确的解决方案（也称为标记）。</li>
<li>最常见的监督学习任务是：分类 和 回归。</li>
<li>最常见的非监督学习算法：聚类、可视化、数据降维 和 关联规则学习。</li>
<li>增强学习。</li>
<li>如果你不知道该如何定义组，你可以使用聚类算法（非监督学习）将你的顾客分成对个组。如果你知道要将这些数据分成哪几组，你可以将属于每个组的实例取出一些，打上标记，用分类（监督学习）对它们进行学习，之后模型就能将你的所有顾客划分到这些组中。</li>
<li>垃圾邮件检测是典型的监督学习问题，需要为算法提供很多带标记（垃圾邮件/普通邮件）的邮件。</li>
<li>相对于批量学习，在线学习系统能够进行增量式的学习。这使它有能力自动适应变化的数据，也能够训练非常大量的数据。</li>
<li>在海量的数据不能同时装载到内存时，可以使用核外学习算法。核外学习算法将训练数据切分成许多的小批量数据，通过在线学习的方法对这些小批量数据集进行训练。</li>
<li>基于实例的学习系统。</li>
<li>一个模型有一个或多个模型参数，这些模型参数确定了当新实例到来时所输出的结果（例如线性模型中的斜率），学习算法就是要找出这些参数的最优值以使得模型具有好的泛化性能。超参数是学习算法的参数，不是模型的参数（例如用于实现正规化的参数）。</li>
<li>基于模型的学习算法是寻找一组能够使模型具有好的泛化能力的参数。我们通常通过最小化在训练集上的代价来训练这种系统，当有正规化时，如果模型太过复杂，代价函数也会变大。在做预测时，我们将新实例的特征向量代入到模型函数中即可，模型函数中参数就是训练得到的。</li>
<li>缺少数据；数据质量不高；非典型性数据；无意义的特征属性；模型太简单造成的欠拟合；模型太复杂造成的过拟合。</li>
<li>可能是由于过拟合造成。解决方法有：获得更多的数据，简化模型(选择更简单的模型、减少模型中的参数个数、对模型正规化)，对数据进行预处理以减少训练集中的噪声。</li>
<li>测试集用于在模型装载到生产环境之前，测试其泛化误差。</li>
<li>确认集用于对模型的比较。用它可以选出最佳的模型和超参数。</li>
<li>如果你用测试集来调整超参数，你可能会过拟合测试集，这会使泛化误差非常大（也许你最终加载的模型性能比你的预计要差）</li>
<li>交叉验证是一种挑选模型的技术（用于选择超参数和模型），但不需要从训练集中特意划分出一部分数据作为确认集，这也节约了训练数据。</li>
</ol>

      </div>
      <div class="md-sidebar-toc"><ul>
<li><a href="#%E7%94%A8scikit-learn%E5%92%8Ctensorflow%E5%AE%9E%E8%B7%B5%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0">用Scikit-Learn和TensorFlow实践机器学习</a>
<ul>
<li><a href="#%E5%89%8D%E8%A8%80">前言</a>
<ul>
<li><a href="#%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%B5%B7%E5%95%B8">机器学习的海啸</a></li>
<li><a href="#%E4%BD%A0%E9%A1%B9%E7%9B%AE%E4%B8%AD%E7%9A%84%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0">你项目中的机器学习</a></li>
<li><a href="#%E7%9B%AE%E6%A0%87%E5%92%8C%E6%96%B9%E6%B3%95">目标和方法</a></li>
<li><a href="#%E5%89%8D%E6%8F%90">前提</a></li>
<li><a href="#%E8%B7%AF%E6%A0%87">路标</a></li>
<li><a href="#%E5%85%B6%E4%BB%96%E8%B5%84%E6%BA%90">其他资源</a></li>
<li><a href="#%E6%9C%AC%E4%B9%A6%E4%B8%AD%E4%BD%BF%E7%94%A8%E7%9A%84%E6%83%AF%E4%BE%8B">本书中使用的惯例</a></li>
<li><a href="#%E4%BD%BF%E7%94%A8%E4%BB%A3%E7%A0%81%E7%A4%BA%E4%BE%8B">使用代码示例</a></li>
<li><a href="#oreilly-safari">O'Reilly Safari</a></li>
<li><a href="#%E5%A6%82%E4%BD%95%E8%81%94%E7%B3%BB%E6%88%91%E4%BB%AC">如何联系我们</a></li>
<li><a href="#%E9%B8%A3%E8%B0%A2">鸣谢</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#%E7%AC%AC%E4%B8%80%E9%83%A8%E5%88%86-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80">第一部分 机器学习基础</a>
<ul>
<li><a href="#%E7%AC%AC%E4%B8%80%E7%AB%A0-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%BA%B5%E8%A7%88">第一章 机器学习纵览</a>
<ul>
<li><a href="#%E4%BB%80%E4%B9%88%E6%98%AF%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0">什么是机器学习？</a></li>
<li><a href="#%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0">为什么要用机器学习</a></li>
<li><a href="#%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%B3%BB%E7%BB%9F%E7%9A%84%E7%A7%8D%E7%B1%BB">机器学习系统的种类</a></li>
<li><a href="#%E7%9B%91%E7%9D%A3%E9%9D%9E%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0">监督/非监督学习</a>
<ul>
<li><a href="#%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0">监督学习</a></li>
<li><a href="#%E9%9D%9E%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0">非监督学习</a></li>
<li><a href="#%E5%8D%8A%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0">半监督学习</a></li>
<li><a href="#%E5%A2%9E%E5%BC%BA%E5%AD%A6%E4%B9%A0">增强学习</a></li>
</ul>
</li>
<li><a href="#%E6%89%B9%E9%87%8F%E5%AD%A6%E4%B9%A0%E5%92%8C%E5%9C%A8%E7%BA%BF%E5%AD%A6%E4%B9%A0">批量学习和在线学习</a>
<ul>
<li><a href="#%E6%89%B9%E9%87%8F%E5%AD%A6%E4%B9%A0">批量学习</a></li>
<li><a href="#%E5%9C%A8%E7%BA%BF%E5%AD%A6%E4%B9%A0">在线学习</a></li>
</ul>
</li>
<li><a href="#%E5%9F%BA%E4%BA%8E%E5%AE%9E%E4%BE%8B-vs-%E5%9F%BA%E4%BA%8E%E6%A8%A1%E5%9E%8B">基于实例 VS 基于模型</a>
<ul>
<li><a href="#%E5%9F%BA%E4%BA%8E%E5%AE%9E%E4%BE%8B%E5%AD%A6%E4%B9%A0">基于实例学习</a></li>
<li><a href="#%E5%9F%BA%E4%BA%8E%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0">基于模型学习</a></li>
</ul>
</li>
<li><a href="#%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E4%B8%BB%E8%A6%81%E6%8C%91%E6%88%98">机器学习的主要挑战</a>
<ul>
<li><a href="#%E8%AE%AD%E7%BB%83%E6%95%B0%E6%8D%AE%E4%B8%8D%E5%85%85%E8%B6%B3">训练数据不充足</a>
<ul>
<li><a href="#%E6%95%B0%E6%8D%AE%E4%B8%8D%E5%8F%AF%E6%80%9D%E8%AE%AE%E7%9A%84%E8%83%BD%E5%8A%9B">数据不可思议的能力</a></li>
</ul>
</li>
<li><a href="#%E9%9D%9E%E5%85%B8%E5%9E%8B%E8%AE%AD%E7%BB%83%E6%95%B0%E6%8D%AE">非典型训练数据</a></li>
<li><a href="#%E4%B8%80%E4%B8%AA%E8%91%97%E5%90%8D%E7%9A%84%E9%87%87%E6%A0%B7%E5%81%8F%E5%B7%AE%E7%9A%84%E4%BE%8B%E5%AD%90">一个著名的采样偏差的例子</a></li>
</ul>
</li>
<li><a href="#%E4%BD%8E%E8%B4%A8%E9%87%8F%E7%9A%84%E6%95%B0%E6%8D%AE">低质量的数据</a></li>
<li><a href="#%E6%97%A0%E5%85%B3%E7%89%B9%E5%BE%81">无关特征</a></li>
<li><a href="#%E8%AE%AD%E7%BB%83%E6%95%B0%E6%8D%AE%E7%9A%84%E8%BF%87%E6%8B%9F%E5%90%88">训练数据的过拟合</a></li>
<li><a href="#%E8%AE%AD%E7%BB%83%E6%95%B0%E6%8D%AE%E7%9A%84%E6%AC%A0%E6%8B%9F%E5%90%88">训练数据的欠拟合</a></li>
<li><a href="#%E5%9B%9E%E9%A1%BE">回顾</a></li>
<li><a href="#%E6%B5%8B%E8%AF%95%E5%92%8C%E9%AA%8C%E8%AF%81">测试和验证</a>
<ul>
<li><a href="#%E6%B2%A1%E6%9C%89%E5%85%8D%E8%B4%B9%E5%8D%88%E9%A4%90%E7%90%86%E8%AE%BA">没有免费午餐理论</a></li>
</ul>
</li>
<li><a href="#%E7%BB%83%E4%B9%A0">练习</a></li>
</ul>
</li>
<li><a href="#%E7%AC%AC%E4%BA%8C%E7%AB%A0-%E4%BB%8E%E5%A4%B4%E5%88%B0%E5%B0%BE%E5%AE%9E%E8%B7%B5%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E9%A1%B9%E7%9B%AE">第二章 从头到尾实践机器学习项目</a>
<ul>
<li><a href="#%E5%B7%A5%E4%BD%9C%E5%9C%A8%E7%9C%9F%E5%AE%9E%E7%9A%84%E6%95%B0%E6%8D%AE%E4%B9%8B%E4%B8%8A">工作在真实的数据之上</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#%E9%99%84%E5%BD%95a-%E7%BB%83%E4%B9%A0%E7%9A%84%E7%AD%94%E6%A1%88">附录A 练习的答案</a>
<ul>
<li><a href="#%E7%AC%AC%E4%B8%80%E7%AB%A0-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%BA%B5%E8%A7%88-1">第一章 机器学习纵览</a></li>
</ul>
</li>
</ul>
</div>
      <a id="sidebar-toc-btn">≡</a>
    </body>
    
    
    
    
    
    <script>
(function bindTaskListEvent() {
  var taskListItemCheckboxes = document.body.getElementsByClassName('task-list-item-checkbox')
  for (var i = 0; i < taskListItemCheckboxes.length; i++) {
    var checkbox = taskListItemCheckboxes[i]
    var li = checkbox.parentElement
    if (li.tagName !== 'LI') li = li.parentElement
    if (li.tagName === 'LI') {
      li.classList.add('task-list-item')
    }
  }
}())    
</script>
    
<script>

var sidebarTOCBtn = document.getElementById('sidebar-toc-btn')
sidebarTOCBtn.addEventListener('click', function(event) {
  event.stopPropagation()
  if (document.body.hasAttribute('html-show-sidebar-toc')) {
    document.body.removeAttribute('html-show-sidebar-toc')
  } else {
    document.body.setAttribute('html-show-sidebar-toc', true)
  }
})
</script>
      
  </html>