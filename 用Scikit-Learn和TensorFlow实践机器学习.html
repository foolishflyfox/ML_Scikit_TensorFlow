<!DOCTYPE html>
  <html>
    <head>
      <title>用Scikit-Learn和TensorFlow实践机器学习</title>
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width, initial-scale=1.0">
      
      <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.8.3/katex.min.css">
      
      
      
      
      
      
      
      
      

      <style> 
      /**
 * prism.js Github theme based on GitHub's theme.
 * @author Sam Clarke
 */
code[class*="language-"],
pre[class*="language-"] {
  color: #333;
  background: none;
  font-family: Consolas, "Liberation Mono", Menlo, Courier, monospace;
  text-align: left;
  white-space: pre;
  word-spacing: normal;
  word-break: normal;
  word-wrap: normal;
  line-height: 1.4;

  -moz-tab-size: 8;
  -o-tab-size: 8;
  tab-size: 8;

  -webkit-hyphens: none;
  -moz-hyphens: none;
  -ms-hyphens: none;
  hyphens: none;
}

/* Code blocks */
pre[class*="language-"] {
  padding: .8em;
  overflow: auto;
  /* border: 1px solid #ddd; */
  border-radius: 3px;
  /* background: #fff; */
  background: #f5f5f5;
}

/* Inline code */
:not(pre) > code[class*="language-"] {
  padding: .1em;
  border-radius: .3em;
  white-space: normal;
  background: #f5f5f5;
}

.token.comment,
.token.blockquote {
  color: #969896;
}

.token.cdata {
  color: #183691;
}

.token.doctype,
.token.punctuation,
.token.variable,
.token.macro.property {
  color: #333;
}

.token.operator,
.token.important,
.token.keyword,
.token.rule,
.token.builtin {
  color: #a71d5d;
}

.token.string,
.token.url,
.token.regex,
.token.attr-value {
  color: #183691;
}

.token.property,
.token.number,
.token.boolean,
.token.entity,
.token.atrule,
.token.constant,
.token.symbol,
.token.command,
.token.code {
  color: #0086b3;
}

.token.tag,
.token.selector,
.token.prolog {
  color: #63a35c;
}

.token.function,
.token.namespace,
.token.pseudo-element,
.token.class,
.token.class-name,
.token.pseudo-class,
.token.id,
.token.url-reference .token.variable,
.token.attr-name {
  color: #795da3;
}

.token.entity {
  cursor: help;
}

.token.title,
.token.title .token.punctuation {
  font-weight: bold;
  color: #1d3e81;
}

.token.list {
  color: #ed6a43;
}

.token.inserted {
  background-color: #eaffea;
  color: #55a532;
}

.token.deleted {
  background-color: #ffecec;
  color: #bd2c00;
}

.token.bold {
  font-weight: bold;
}

.token.italic {
  font-style: italic;
}


/* JSON */
.language-json .token.property {
  color: #183691;
}

.language-markup .token.tag .token.punctuation {
  color: #333;
}

/* CSS */
code.language-css,
.language-css .token.function {
  color: #0086b3;
}

/* YAML */
.language-yaml .token.atrule {
  color: #63a35c;
}

code.language-yaml {
  color: #183691;
}

/* Ruby */
.language-ruby .token.function {
  color: #333;
}

/* Markdown */
.language-markdown .token.url {
  color: #795da3;
}

/* Makefile */
.language-makefile .token.symbol {
  color: #795da3;
}

.language-makefile .token.variable {
  color: #183691;
}

.language-makefile .token.builtin {
  color: #0086b3;
}

/* Bash */
.language-bash .token.keyword {
  color: #0086b3;
}html body{font-family:"Helvetica Neue",Helvetica,"Segoe UI",Arial,freesans,sans-serif;font-size:16px;line-height:1.6;color:#333;background-color:#fff;overflow:initial;box-sizing:border-box;word-wrap:break-word}html body>:first-child{margin-top:0}html body h1,html body h2,html body h3,html body h4,html body h5,html body h6{line-height:1.2;margin-top:1em;margin-bottom:16px;color:#000}html body h1{font-size:2.25em;font-weight:300;padding-bottom:.3em}html body h2{font-size:1.75em;font-weight:400;padding-bottom:.3em}html body h3{font-size:1.5em;font-weight:500}html body h4{font-size:1.25em;font-weight:600}html body h5{font-size:1.1em;font-weight:600}html body h6{font-size:1em;font-weight:600}html body h1,html body h2,html body h3,html body h4,html body h5{font-weight:600}html body h5{font-size:1em}html body h6{color:#5c5c5c}html body strong{color:#000}html body del{color:#5c5c5c}html body a:not([href]){color:inherit;text-decoration:none}html body a{color:#08c;text-decoration:none}html body a:hover{color:#00a3f5;text-decoration:none}html body img{max-width:100%}html body>p{margin-top:0;margin-bottom:16px;word-wrap:break-word}html body>ul,html body>ol{margin-bottom:16px}html body ul,html body ol{padding-left:2em}html body ul.no-list,html body ol.no-list{padding:0;list-style-type:none}html body ul ul,html body ul ol,html body ol ol,html body ol ul{margin-top:0;margin-bottom:0}html body li{margin-bottom:0}html body li.task-list-item{list-style:none}html body li>p{margin-top:0;margin-bottom:0}html body .task-list-item-checkbox{margin:0 .2em .25em -1.8em;vertical-align:middle}html body .task-list-item-checkbox:hover{cursor:pointer}html body blockquote{margin:16px 0;font-size:inherit;padding:0 15px;color:#5c5c5c;border-left:4px solid #d6d6d6}html body blockquote>:first-child{margin-top:0}html body blockquote>:last-child{margin-bottom:0}html body hr{height:4px;margin:32px 0;background-color:#d6d6d6;border:0 none}html body table{margin:10px 0 15px 0;border-collapse:collapse;border-spacing:0;display:block;width:100%;overflow:auto;word-break:normal;word-break:keep-all}html body table th{font-weight:bold;color:#000}html body table td,html body table th{border:1px solid #d6d6d6;padding:6px 13px}html body dl{padding:0}html body dl dt{padding:0;margin-top:16px;font-size:1em;font-style:italic;font-weight:bold}html body dl dd{padding:0 16px;margin-bottom:16px}html body code{font-family:Menlo,Monaco,Consolas,'Courier New',monospace;font-size:.85em !important;color:#000;background-color:#f0f0f0;border-radius:3px;padding:.2em 0}html body code::before,html body code::after{letter-spacing:-0.2em;content:"\00a0"}html body pre>code{padding:0;margin:0;font-size:.85em !important;word-break:normal;white-space:pre;background:transparent;border:0}html body .highlight{margin-bottom:16px}html body .highlight pre,html body pre{padding:1em;overflow:auto;font-size:.85em !important;line-height:1.45;border:#d6d6d6;border-radius:3px}html body .highlight pre{margin-bottom:0;word-break:normal}html body pre code,html body pre tt{display:inline;max-width:initial;padding:0;margin:0;overflow:initial;line-height:inherit;word-wrap:normal;background-color:transparent;border:0}html body pre code:before,html body pre tt:before,html body pre code:after,html body pre tt:after{content:normal}html body p,html body blockquote,html body ul,html body ol,html body dl,html body pre{margin-top:0;margin-bottom:16px}html body kbd{color:#000;border:1px solid #d6d6d6;border-bottom:2px solid #c7c7c7;padding:2px 4px;background-color:#f0f0f0;border-radius:3px}@media print{html body{background-color:#fff}html body h1,html body h2,html body h3,html body h4,html body h5,html body h6{color:#000;page-break-after:avoid}html body blockquote{color:#5c5c5c}html body pre{page-break-inside:avoid}html body table{display:table}html body img{display:block;max-width:100%;max-height:100%}html body pre,html body code{word-wrap:break-word;white-space:pre}}.markdown-preview{width:100%;height:100%;box-sizing:border-box}.markdown-preview .pagebreak,.markdown-preview .newpage{page-break-before:always}.markdown-preview pre.line-numbers{position:relative;padding-left:3.8em;counter-reset:linenumber}.markdown-preview pre.line-numbers>code{position:relative}.markdown-preview pre.line-numbers .line-numbers-rows{position:absolute;pointer-events:none;top:1em;font-size:100%;left:0;width:3em;letter-spacing:-1px;border-right:1px solid #999;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none}.markdown-preview pre.line-numbers .line-numbers-rows>span{pointer-events:none;display:block;counter-increment:linenumber}.markdown-preview pre.line-numbers .line-numbers-rows>span:before{content:counter(linenumber);color:#999;display:block;padding-right:.8em;text-align:right}.markdown-preview .mathjax-exps .MathJax_Display{text-align:center !important}.markdown-preview:not([for="preview"]) .code-chunk .btn-group{display:none}.markdown-preview:not([for="preview"]) .code-chunk .status{display:none}.markdown-preview:not([for="preview"]) .code-chunk .output-div{margin-bottom:16px}.scrollbar-style::-webkit-scrollbar{width:8px}.scrollbar-style::-webkit-scrollbar-track{border-radius:10px;background-color:transparent}.scrollbar-style::-webkit-scrollbar-thumb{border-radius:5px;background-color:rgba(150,150,150,0.66);border:4px solid rgba(150,150,150,0.66);background-clip:content-box}html body[for="html-export"]:not([data-presentation-mode]){position:relative;width:100%;height:100%;top:0;left:0;margin:0;padding:0;overflow:auto}html body[for="html-export"]:not([data-presentation-mode]) .markdown-preview{position:relative;top:0}@media screen and (min-width:914px){html body[for="html-export"]:not([data-presentation-mode]) .markdown-preview{padding:2em calc(50% - 457px)}}@media screen and (max-width:914px){html body[for="html-export"]:not([data-presentation-mode]) .markdown-preview{padding:2em}}@media screen and (max-width:450px){html body[for="html-export"]:not([data-presentation-mode]) .markdown-preview{font-size:14px !important;padding:1em}}@media print{html body[for="html-export"]:not([data-presentation-mode]) #sidebar-toc-btn{display:none}}html body[for="html-export"]:not([data-presentation-mode]) #sidebar-toc-btn{position:fixed;bottom:8px;left:8px;font-size:28px;cursor:pointer;color:inherit;z-index:99;width:32px;text-align:center;opacity:.4}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] #sidebar-toc-btn{opacity:1}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc{position:fixed;top:0;left:0;width:300px;height:100%;padding:32px 0 48px 0;font-size:14px;box-shadow:0 0 4px rgba(150,150,150,0.33);box-sizing:border-box;overflow:auto;background-color:inherit}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc::-webkit-scrollbar{width:8px}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc::-webkit-scrollbar-track{border-radius:10px;background-color:transparent}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc::-webkit-scrollbar-thumb{border-radius:5px;background-color:rgba(150,150,150,0.66);border:4px solid rgba(150,150,150,0.66);background-clip:content-box}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc a{text-decoration:none}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc ul{padding:0 1.6em;margin-top:.8em}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc li{margin-bottom:.8em}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc ul{list-style-type:none}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .markdown-preview{left:300px;width:calc(100% -  300px);padding:2em calc(50% - 457px -  150px);margin:0;box-sizing:border-box}@media screen and (max-width:1274px){html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .markdown-preview{padding:2em}}@media screen and (max-width:450px){html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .markdown-preview{width:100%}}html body[for="html-export"]:not([data-presentation-mode]):not([html-show-sidebar-toc]) .markdown-preview{left:50%;transform:translateX(-50%)}html body[for="html-export"]:not([data-presentation-mode]):not([html-show-sidebar-toc]) .md-sidebar-toc{display:none}
/* Please visit the URL below for more information: */
/*   https://shd101wyy.github.io/markdown-preview-enhanced/#/customize-css */
 
      </style>
    </head>
    <body for="html-export">
      <div class="mume markdown-preview   ">
      <h1 class="mume-header" id="%E7%94%A8scikit-learn%E5%92%8Ctensorflow%E5%AE%9E%E8%B7%B5%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0">用Scikit-Learn和TensorFlow实践机器学习</h1>

<p>@(Python)[python库, 机器学习, Scikit-learn, TensorFlow]</p>
<blockquote>
<p>观点、工具和技术，建立一个智能系统</p>
</blockquote>
<p><strong>译者所用的Python版本号为3.6.2，原书中的很多代码已经在该版本的Python下不能正常运行，故在翻译的同时做了少量修改</strong></p>
<ul>
<li><a href="#%E7%94%A8scikit-learn%E5%92%8Ctensorflow%E5%AE%9E%E8%B7%B5%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0">用Scikit-Learn和TensorFlow实践机器学习</a>
<ul>
<li><a href="#%E5%89%8D%E8%A8%80">前言</a>
<ul>
<li><a href="#%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%B5%B7%E5%95%B8">机器学习的海啸</a></li>
<li><a href="#%E4%BD%A0%E9%A1%B9%E7%9B%AE%E4%B8%AD%E7%9A%84%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0">你项目中的机器学习</a></li>
<li><a href="#%E7%9B%AE%E6%A0%87%E5%92%8C%E6%96%B9%E6%B3%95">目标和方法</a></li>
<li><a href="#%E5%89%8D%E6%8F%90">前提</a></li>
<li><a href="#%E8%B7%AF%E6%A0%87">路标</a></li>
<li><a href="#%E5%85%B6%E4%BB%96%E8%B5%84%E6%BA%90">其他资源</a></li>
<li><a href="#%E6%9C%AC%E4%B9%A6%E4%B8%AD%E4%BD%BF%E7%94%A8%E7%9A%84%E6%83%AF%E4%BE%8B">本书中使用的惯例</a></li>
<li><a href="#%E4%BD%BF%E7%94%A8%E4%BB%A3%E7%A0%81%E7%A4%BA%E4%BE%8B">使用代码示例</a></li>
<li><a href="#oreilly-safari">O'Reilly Safari</a></li>
<li><a href="#%E5%A6%82%E4%BD%95%E8%81%94%E7%B3%BB%E6%88%91%E4%BB%AC">如何联系我们</a></li>
<li><a href="#%E9%B8%A3%E8%B0%A2">鸣谢</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#%E7%AC%AC%E4%B8%80%E9%83%A8%E5%88%86-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80">第一部分 机器学习基础</a>
<ul>
<li><a href="#%E7%AC%AC%E4%B8%80%E7%AB%A0-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%BA%B5%E8%A7%88">第一章 机器学习纵览</a>
<ul>
<li><a href="#%E4%BB%80%E4%B9%88%E6%98%AF%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0">什么是机器学习？</a></li>
<li><a href="#%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0">为什么要用机器学习</a></li>
<li><a href="#%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%B3%BB%E7%BB%9F%E7%9A%84%E7%A7%8D%E7%B1%BB">机器学习系统的种类</a></li>
<li><a href="#%E7%9B%91%E7%9D%A3%E9%9D%9E%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0">监督/非监督学习</a>
<ul>
<li><a href="#%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0">监督学习</a></li>
<li><a href="#%E9%9D%9E%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0">非监督学习</a></li>
<li><a href="#%E5%8D%8A%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0">半监督学习</a></li>
<li><a href="#%E5%A2%9E%E5%BC%BA%E5%AD%A6%E4%B9%A0">增强学习</a></li>
</ul>
</li>
<li><a href="#%E6%89%B9%E9%87%8F%E5%AD%A6%E4%B9%A0%E5%92%8C%E5%9C%A8%E7%BA%BF%E5%AD%A6%E4%B9%A0">批量学习和在线学习</a>
<ul>
<li><a href="#%E6%89%B9%E9%87%8F%E5%AD%A6%E4%B9%A0">批量学习</a></li>
<li><a href="#%E5%9C%A8%E7%BA%BF%E5%AD%A6%E4%B9%A0">在线学习</a></li>
</ul>
</li>
<li><a href="#%E5%9F%BA%E4%BA%8E%E5%AE%9E%E4%BE%8B-vs-%E5%9F%BA%E4%BA%8E%E6%A8%A1%E5%9E%8B">基于实例 VS 基于模型</a>
<ul>
<li><a href="#%E5%9F%BA%E4%BA%8E%E5%AE%9E%E4%BE%8B%E5%AD%A6%E4%B9%A0">基于实例学习</a></li>
<li><a href="#%E5%9F%BA%E4%BA%8E%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0">基于模型学习</a></li>
</ul>
</li>
<li><a href="#%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E4%B8%BB%E8%A6%81%E6%8C%91%E6%88%98">机器学习的主要挑战</a>
<ul>
<li><a href="#%E8%AE%AD%E7%BB%83%E6%95%B0%E6%8D%AE%E4%B8%8D%E5%85%85%E8%B6%B3">训练数据不充足</a>
<ul>
<li><a href="#%E6%95%B0%E6%8D%AE%E4%B8%8D%E5%8F%AF%E6%80%9D%E8%AE%AE%E7%9A%84%E8%83%BD%E5%8A%9B">数据不可思议的能力</a></li>
</ul>
</li>
<li><a href="#%E9%9D%9E%E5%85%B8%E5%9E%8B%E8%AE%AD%E7%BB%83%E6%95%B0%E6%8D%AE">非典型训练数据</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 class="mume-header" id="%E5%89%8D%E8%A8%80">前言</h2>

<h3 class="mume-header" id="%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%B5%B7%E5%95%B8">机器学习的海啸</h3>

<p>2006年，Geoffrey Hinton 等人发表了一篇文章，说明了如何通过训练一个深度神经网络的能力来识别手写数字，正确率达到了惊人的98% 。他们称这种技术为 <strong>深度学习</strong>。在当时，训练一个深度神经网络被广泛认为是不可能的，因此，大多数的也就是从19世纪90年代就放弃了这种想法。这篇论文重新勾起了科学社区对深度学习的兴趣。新论文的不断涌现，展示了深度学习不仅可能用于应用，而且其令人兴奋的成绩是其他的机器学习(ML)技术所不能比拟的（主要得益于现今海量的数据的超大的计算能力）。这种热情很快扩展到机器学习的其他领域。</p>
<p>10年时间匆匆而逝，机器学习也已经征服了很多的产业：现在很多的高科技产品的核心就是机器学习，比如网络搜索结果的排序，智能手机的语音识别、电影的推荐系统、alpha狗的围棋大战，还有汽车的自动驾驶领域。</p>
<h3 class="mume-header" id="%E4%BD%A0%E9%A1%B9%E7%9B%AE%E4%B8%AD%E7%9A%84%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0">你项目中的机器学习</h3>

<p>我想，你应该会对机器学习感兴趣，并且会享受加入到这场盛宴的过程中！</p>
<p>也许你希望赋予自己DIY的机器人一个大脑，使它能够识别人脸，或者学着在四周走来走去。</p>
<p>或者，也许你的公司有着海量的数据（用户的日志，财务数据，生产数据，机器传感器的数据，热线统计数据，HR的报表等等），你要你知道如何去找，你就能从这一大堆的数据中挖掘出隐藏的 “宝石”，比如：</p>
<ul>
<li>将所有消费者划分成多个组，对每个组制定最佳的营销策略</li>
<li>根据消费者的消费记录，推荐其相似类型的产品</li>
<li>自动检测存在欺诈行为的交易</li>
<li>预测下一年的收入</li>
<li>... ...</li>
</ul>
<p>不过你是基于以上的什么原因，你应该已经决定去学机器学习，并且在你的项目中实现它。嗯，很好的想法！</p>
<h3 class="mume-header" id="%E7%9B%AE%E6%A0%87%E5%92%8C%E6%96%B9%E6%B3%95">目标和方法</h3>

<p>该书假定你几乎对机器学习毫无了解，它的目标是为你 <em>从数据中学习</em> 的编程中提供必需的概念、直觉和工具。</p>
<p>我们将涉及大量的技术，从最简单、最常用的技术（比如线性回归）到一些经常能赢得比赛的深度学习技术。</p>
<p>与其自己通过动手实现一个简陋的机器学习模型，我们更多的是使用现成的Python框架：</p>
<ul>
<li>
<p><code>Scikit-Learn</code> 非常容易使用，而且它非常高效地实现了许多的机器学习算法，可以说该库大大降低了机器学习的准入门槛。</p>
</li>
<li>
<p><code>TensorFlow</code> 是一个更加复杂的库，该库通过数据流图的方式实现分布式数值计算。它通过分布式计算将计算量分配到成千上万的多GPU服务端，使得高效地训练非常大型的神经网络称为了可能。TensorFlow由Google公司创建，并且支持他们的很多大规模机器学习的应用。该库于2015年11月开源。</p>
</li>
</ul>
<p>本书采用实践的方式，通过具体的可以工作的例子和少量的理论来使读者对机器学习产生直觉上的理解。如果你在阅读该书时没有带上你的笔记本，我们强烈建议通过在线的 Jupyter notebooks （网址为：<a href="https://github.com/ageron/handson-ml%EF%BC%89%E4%B8%8A%E5%AE%9E%E9%AA%8C%E4%BE%8B%E5%AD%90%E4%B8%AD%E7%9A%84%E4%BB%A3%E7%A0%81%E3%80%82">https://github.com/ageron/handson-ml）上实验例子中的代码。</a></p>
<h3 class="mume-header" id="%E5%89%8D%E6%8F%90">前提</h3>

<p>本书假定你有一些 Python 的编程经验，并且也熟悉 Python 中的一些主要的科学库 <code>NumPy</code>，<code>Pandas</code> 和 <code>Matplotlib</code> 。</p>
<p>另外，你也需要一些大学级别的数学知识，比如微积分、线性代数、概率论和统计学。</p>
<p>如果你现在还不知道Python，<a href="http://learnpython.org">http://learnpython.org</a> 是一个不错的学习网站。官方教程 <a href="https://www.python.org">https://www.python.org</a> 也是一个非常好的选择。</p>
<p>如果你从来没有用过 Jupyter， 第二章将会引导你安装和基本的使用方法，这是一个你值得拥有的工具。</p>
<p>如果你不熟悉 Python 的科学库，在 Jupyter notebooks 中包含了一些教程，是一些关于线性代数的快速教程。</p>
<h3 class="mume-header" id="%E8%B7%AF%E6%A0%87">路标</h3>

<p>该书组织成两个部分。</p>
<p>第一部分：<strong>机器学习的基础</strong>，包括以下内容：</p>
<ul>
<li>什么是机器学习？它解决的是什么问题？机器学习系统分为哪些类？有哪些基本的概念？</li>
<li>一个经典的机器学习项目需要哪些主要的步骤？</li>
<li>学习如何让模型逼近数据</li>
<li>最优化损失函数</li>
<li>处理、清洗和预处理数据</li>
<li>选择和设计特征</li>
<li>选择一个训练模型，通过交叉验证来调节超参数</li>
<li>机器学习的主要挑战，特别是欠拟合和过拟合（偏差和方差的权衡）</li>
<li>对训练数据进行降维，尽量减少维度灾难的风险</li>
<li>最常用的学习算法：多项式线性回归模型、逻辑回归模型、k近邻模型、支持向量机模型、决策树模型、随机森林和集成方法</li>
</ul>
<p>第二部分：<strong>神经网络和深度学习</strong>，包括如下主题：</p>
<ul>
<li>什么是神经网络？它们有什么优点？</li>
<li>用TensorFlow建立并训练神经网络</li>
<li>最重要的神经网络结构：前馈神经网络（FNN）、卷积神经网络（CNN）、循环神经网络（RNN）、长短期记忆网络（LSTM）和 自编码（auto-encoders）</li>
<li>训练深度神经网络的技术</li>
<li>大数据集的大规模神经网络</li>
<li>增强学习</li>
</ul>
<p>第一部分更多的使用Scikit-Learn库，第二部分重要使用Tensor-Flow。</p>
<p>**注意：**各位同志不要着急入坑：深度学习毫无疑问是在所有的机器学习方法中最令人兴奋的，但首先你应该掌握基础的原理。而且，多数的问题能够通过使用更简单的技术，例如：随机森林、集成方法（将会在第一部分进行讨论）进行很好的解决。深度学习更适合于复杂的问题，例如图像识别、语音识别或者是自然语言处理，对于这些问题，你必须提供足够的数据、计算能力以及耐心。</p>
<h3 class="mume-header" id="%E5%85%B6%E4%BB%96%E8%B5%84%E6%BA%90">其他资源</h3>

<p>学习机器学习的资源有很多，例如吴恩达教授在<a href="https://www.coursera.org/learn/machine-learning/">Coursera 上的机器学习课程</a>，Geoffrey Hinton 等人的<a href="https://www.coursera.org/learn/neural-networks">神经网络与机器学习</a>都非常棒，尽管这些课程都需要投入大量的时间去消化（大概够你想几个月吧）。</p>
<p>关于机器学习，还有许多有趣的网站，包括Scikit-Learn官网上的<a href="http://scikit-learn.org/stable/user_guide.html">用户指南</a>。你也许还会喜欢 <a href="https://www.dataquest.io/">Dataquest</a> 网站，它提供了优雅的交互式教程，想看更多关于机器学习的博客的话，可以查看<a href="https://www.quora.com/What-are-the-best-regularly-updated-machine-learning-blogs-or-resources-available">Quora</a>上的这个列表。最后，<a href="http://deeplearning.net/">Deep Learning website</a>列出了很多优质的资源供你更深入地学习。</p>
<p>当然，还有许多介绍机器学习的书籍，特别需要列出的有：</p>
<ul>
<li>Joel Grus, <a href="http://shop.oreilly.com/product/0636920033400.do">Data Science from Scratch</a>，O'Reilly出版社出版，中文名为《数据科学入门》，该书介绍了机器学习的基本原理，<strong>并用纯Python语言实现了其中主要的算法</strong>（正如书名所说的，从零开始）</li>
<li>Stephen Marsland, <a href="https://book.douban.com/subject/3887824/">Machine Learning: An Algorithmic Perspective</a>，英国的CRC（Chapman and Hall）出版社出版。该书对机器学习的介绍还是很有深度的，也提供了Python 的代码实现（也是从零开始，不过是用Numpy库）</li>
<li>Sebastian Raschka，<a href="https://book.douban.com/subject/26629312/">Python Machine Learning</a>，Packt出版社出版，该书对机器学习的介绍也非常棒，其中的代码实现主要借助了开源的库：Pylearn 2 和 Theano</li>
<li>Yaser S. Abu-Mostafa, Malik Magdon-Ismail, 和 Hsuan-Tien Lin，<a href="https://book.douban.com/subject/11026330/">Learning from Data</a>  AMLBook 出版社出版。该书是对机器学习进行了理论化的介绍，具有非常深刻的见解，特别是第四章的<em>偏差-方差权衡</em></li>
<li>Stuart Russell, Peter Norvig, <a href="https://book.douban.com/subject/5378558/">Artificial Intelligence: A Modern Approach, 3rd Edition</a>。该书真的是一本关于人工智能的大部头的书，而且其中涉及的论题数量也非常惊人，其中包括了机器学习，它能带你从整个人工智能的角度来审视机器学习的位置</li>
</ul>
<p>最后，一种 &quot;速成&quot; 的方式是注册一个机器学习比赛网站的账号，比如 <a href="https://www.kaggle.com/">Kaggle.com</a>，它将为你提供解决一个真实世界问题的实践平台，同时也可以得到很多机器学习顶级专家的帮助。</p>
<h3 class="mume-header" id="%E6%9C%AC%E4%B9%A6%E4%B8%AD%E4%BD%BF%E7%94%A8%E7%9A%84%E6%83%AF%E4%BE%8B">本书中使用的惯例</h3>

<p>以下是本书中的使用的印刷规范：</p>
<p>斜体（<em>Italic</em>）<br>
        表示新的术语、URLs、email地址、文件名和文件扩展。</p>
<p>等宽 （<code>Constant width</code>）<br>
       用于程序列表的现实，也可能是出现在段落内的程序元素，比如变量、函数名、数据库、数据类型、环境变量、声明及关键字。</p>
<p>等宽加粗（<strong><code>Constant width</code></strong>）<br>
        用于显示命令或者是其他的用户需要手动逐字输入的文本。</p>
<p>等宽斜体（<em><code>Content width</code></em>）<br>
       用于显示可替换的文本，这些文本需要用户提供或者是需要根据具体的语境生成。</p>
<p><img src="./asset/suggest.png" alt="Alt text"> 该图案表示 <strong>提示</strong> 或 <strong>建议</strong></p>
<p><img src="./asset/note.png" alt="Alt text"> 该图案表示通常的 <strong>注释</strong></p>
<p><img src="./asset/warning.png" alt="Alt text"> 该图案表示一个 <strong>警告</strong> 或 <strong>注意点</strong></p>
<h3 class="mume-header" id="%E4%BD%BF%E7%94%A8%E4%BB%A3%E7%A0%81%E7%A4%BA%E4%BE%8B">使用代码示例</h3>

<p>本书所提供所有材料（包括代码示例、练习等），都可以从https://github.com/ageron/handson-ml 下载下来。</p>
<p>本书是为了帮助你刚好地完成工作。所以，如果你需要在你的代码或文档中使用本书提供的案例代码，通常不需要联系我们以获取许可。除非你需要非常大量的代码。例如，如果你仅仅是需要使用几个代码块，自然不需要获取许可。回答问题是引用了示例代码也不需要获得许可。但是，如果需要将大量的实例代码组织起来合并到你的产品文件中，就需要获得我们的许可了。</p>
<p>在使用代码时，我们感激但并不强制注明出处。出处通常应该包括书名，作者，出版社和 ISBN。例如：“<em>Hands-on Machine Learning with Scikit-Learn and TensorFlow</em> by Aurelien Geron (O'Reilly)，Copyright 2017, Aurelien Geron, 978-1-491-96229-9”</p>
<p>如果你感觉自己将其中的代码超过了合理利用的范围，或者是超过了上述的使用权限，敬请联系我们：<a href="permissions@oreilly.com"><em>permissions@oreilly.com</em></a></p>
<h3 class="mume-header" id="oreilly-safari">O'Reilly Safari</h3>

<p><img src="./asset/1516620405430.png" alt="Alt text"><br>
<a href="http://oreilly.com/safari">Safari</a>（原先是Safari Books Online）是一个针对企业、政府机关、教育机构以及个人的基于会员制的培训和参考平台。</p>
<p>会员能够获得上千的书籍、培训视频、学习途径、交互教程以及超过250家出版社的出版清单，包括 O'Reilly Media, Harvard Business Review, Prentice Hall Professional, Addison-Wesley Profes‐ sional, Microsoft Press, Sams, Que, Peachpit Press, Adobe, Focal Press, Cisco Press,ohn Wiley &amp; Sons, Syngress, Morgan Kaufmann, IBM Redbooks, Packt, Adobe Press, FT Press, Apress, Manning, New Riders, McGraw-Hill, Jones &amp; Bartlett 和 Course Technology 等等。</p>
<p>详情请访问：<a href="http://oreilly.com/safari%E3%80%82">http://oreilly.com/safari。</a></p>
<h3 class="mume-header" id="%E5%A6%82%E4%BD%95%E8%81%94%E7%B3%BB%E6%88%91%E4%BB%AC">如何联系我们</h3>

<p>请将关于本书的评论和问题发送到出版社，地址为：</p>
<p>        O’Reilly Media, Inc.<br>
        1005 Gravenstein Highway North<br>
        Sebastopol, CA 95472<br>
        800-998-9938 (in the United States or Canada)<br>
        707-829-0515 (international or local)<br>
        707-829-0104 (fax)</p>
<p>关于本书的勘误表、例子以及如何附加的信息都会放在我们的网站上，地址为：<a href="https://bit.ly/hands-on-machine-learning-with-scikit-learn-and-tensorow%E3%80%82">https://bit.ly/hands-on-machine-learning-with-scikit-learn-and-tensorow。</a></p>
<p>如果想咨询关于本书的技术问题，请发邮件至：[bookques‐ <a href="mailto:tions@oreilly.com">tions@oreilly.com</a>](bookques‐ <a href="mailto:tions@oreilly.com">tions@oreilly.com</a>)。</p>
<p>更多的有关我们的出版物、课程、讨论会、新闻的内容，请访问我们的网站：<a href="http://www.oreilly.com">http://www.oreilly.com</a>。</p>
<p>在facebook上找到我们：<a href="http://facebook.com/oreilly">http://facebook.com/oreilly</a></p>
<p>订阅我们的Twitter：<a href="http://twitter.com/oreillymedia">http://twitter.com/oreillymedia</a></p>
<p>在YouTube上找到我们：<a href="http://www.youtube.com/oreillymedia">http://www.youtube.com/oreillymedia</a></p>
<h3 class="mume-header" id="%E9%B8%A3%E8%B0%A2">鸣谢</h3>

<p>我要感谢我在Google公司的同事，特别是YouTube视频分类小组的小伙伴们，你们教会了我那么多关于机器学习的知识，如果没有你们，我将不可能写成这本书。特别的感谢留给我的机器学习导师：Clement Courbet，Julien Dubois，Mathias Kende，Daniel Kitachewsky，James Pack，Alexander Pak，Anosh Raj，Vitor Sessak，Wiktor Tomczak，Ingrid von Glehn，Rich Washington	在 YouTube Pairs 中的每一位。</p>
<p>我也非常感激所有能够在百忙之中抽出时间仔细校对这本书的人。感谢 Pete Warden ，他作为 TensorFlow团队中的核心成员，回答了我所有关于TensorFlow的问题，校对了第二部分，并提供了许多有趣的想法。你一定得去访问一下他的<a href="https://petewarden.com/">博客</a>。感谢Lukas Biewald，他非常彻底的校对了第二部分：测试了所有的代码，提出了许多的建议，他的热情深深感染了我。你应该访问他的<a href="https://lukasbiewald.com/">博客</a> 和他<a href="https://www.oreilly.com/learning/how-to-build-a-robot-that-sees-with-100-and-tensorflow">库库的机器人</a>。感谢 Justin Francis，他完全地校对了第二部分，找出了许多的错误并提供了许多想法，特别是在16章中，可以查看他关于TensorFlow的<a href="https://www.oreilly.com/people/justin-francis">帖子</a>。</p>
<p>非常感谢 David Andrzejewski，他校对了第一部分，并提供了大量有用反馈，指出了其中写得含糊不清的部分，并建议如何进行改进。查看他的<a href="http://www.david-andrzejewski.com/">网站</a>。感谢 Gregoire Mesnil，校对了第二部分，在关于训练神经网络方面贡献了非常有趣和实用的建议。也感谢Eddy Hung，Salim Semaoune，Karim Matrah，Ingrid von Glehn，Iain Smears 和 Vincent Guilbeau，他们校对了第一部分，并提出了许多有用的建议。我也必须感谢我的岳父 Michel Tessier，以及之前是我数学老师现在是优秀的翻译者的 Anton Chekhov，帮助我解决了许多数学以及符号方面的问题，并校验了关于Jupyter notebook线性代数部分的内容。</p>
<p>当然，万分感谢我亲爱的兄弟Sylvain，他校对了每一个章节，并测试了其中的每一行代码，并几乎在每个章节都提供了反馈，并从写书之初到之后都一直支持我。爱你，哥！</p>
<p>非常感谢 O'Reilly 非常棒的工作人员，特别是Nicole Tache，给了我许多富有洞察力的反馈。同时也感谢Marie Beaugureau，Bea Lorica，Mike Loukides 和 Laurel Ruma，一直相信这个项目，并未为本书明确了着眼点。感谢 Matt Hacker 和所有 Atlas 组的成员，回答了我关于格式、asciidoc 和 LaTeX 的问题。感谢Rachel Monaghan，Nick Adams 和所有产品组的成员，帮我完成了最终的审稿并做了许多的改正。</p>
<p>最后但同样重要的，我非常非常感谢我亲爱的妻子，Emmanuelle 和我们3个可爱的孩子，Alexandre，Aemi 和 Gabrielle，鼓励我努力完成这本书，问了我许多的问题（谁说不能教7岁小孩学习神经网络），为我提供饼干和咖啡，有此待遇，夫复何求？</p>
<h1 class="mume-header" id="%E7%AC%AC%E4%B8%80%E9%83%A8%E5%88%86-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80">第一部分 机器学习基础</h1>

<h2 class="mume-header" id="%E7%AC%AC%E4%B8%80%E7%AB%A0-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%BA%B5%E8%A7%88">第一章 机器学习纵览</h2>

<p>大多数人听到 “机器学习” 时，大脑中应该会浮现出一个机器人：可信赖的管家或者是致命的终结者，都随你怎么称呼。但是机器学习并仅仅是未来的一个奇迹。事实上，它已经在某些特殊的应用场景中存在了几十年，例如光学字符识别（Optical Character Recognition, OCR）。但是机器学习的应用第一次成为主流，改善千万人的生活需要追溯到上世纪的90年代：垃圾邮件过滤器。它并不是一个有自我意识的天网，但是在技术层面的确是一个合格的机器学习应用（它实际上已经几乎不需要你标出垃圾邮件了）。它被许多的机器学习应用所效仿，并默默影响着成百上千的你所经常使用的功能，从更好的推荐系统到语义检索。</p>
<p>机器学习从何而来，又将归于何处？机器学习到底学的是什么东西？如果我把维基百科下载下来，那是不是我的电脑就称为学到了一些东西？它是突变的智能吗？在本章，我们将阐明什么是机器学习以及为什么你可能要学习它？</p>
<p>在我们开始探索机器学习这块未知的大陆之前，我们先了解一下它主要的划分和最显著的“路标”：监督学习 vs 非监督学习，在线学习 vs 批量学习。之后，我们将会看到一个典型的机器学习项目的工作流程，讨论你可能需要面对的主要挑战，包括如何去评价和微调一个机器学习系统。</p>
<p>本章将介绍每个数据科学家需要真正理解的许多基本概念（和行话），本章只是一个高度概述（不涉及很多代码），所有的内容都非常简单，但是你应当确保在阅读其他章节之前，对本章的所有内容都非常明白。来杯咖啡，让我们开干吧！</p>
<blockquote>
<p>如果你已经对机器学习的基本概念都了解清楚了，你可以跳到第二章继续阅读。如果你不是非常确定，就在跳转之前先尝试回答在本章最后所列出的所有问题。</p>
</blockquote>
<h3 class="mume-header" id="%E4%BB%80%E4%B9%88%E6%98%AF%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0">什么是机器学习？</h3>

<p>机器学习是计算机编程的科学（和艺术），程序能从数据中进行学习。</p>
<p>以下是一个常见的定义：</p>
<blockquote>
<p>机器学习是不通过显式地编程而让计算机获得某种能力的领域。<br>
------ Arthur Samuel，1959</p>
</blockquote>
<p>而更加工程化的描述为：</p>
<blockquote>
<p>对于某类任务T和性能度量P，如果一个计算机程序在T上以P衡量的性能随着经验E而自我完善，那么我们称这个计算机程序在从经验E学习<br>
------ Tom Mitchell，1997</p>
</blockquote>
<p>比如说，你的垃圾邮件过滤器就是一个机器学习的程序，它能够学着去标记一封邮件是不是垃圾邮件，而最初由用户给这些邮件打上标记供机器学习。供系统使用的所有训练案例称为训练集，每个单独的训练案例称为训练实例（或称为采样）。在这个例子中，任务T就是为一封新邮件打上标记，经验E是训练集中的数据，性能衡量P需要被定义；比如，你可以用邮件分类正确的比率来作为P，这种特殊的性能衡量指标称为正确率，它常常被用于分类的任务中。</p>
<p>如果你只是将维基百科的一个拷贝下载下来，你的电脑有很多的数据，但是它不会立即具备测试某个实例的能力。因此，这种行为并不是机器学习。</p>
<h3 class="mume-header" id="%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0">为什么要用机器学习</h3>

<p>想象一下，如何用传统的方法来编写邮件过滤器（如图1-1所示）：</p>
<ol>
<li>第一步，你需要确定垃圾邮件的典型特征。你也许会注意到包含一些特定的单词或短语（例如 “4U”，“信用卡”，“免费”，“惊人的”）会在某一主题中被多次提到。也许你也会注意到在发送人的名字中、邮件格式中的一些其他模式等等。</li>
<li>你需要为你所留意到的每一种模式写检测代码，之后你的程序根据检测到这些模式的数量来决策该邮件是否是垃圾邮件。</li>
<li>你需要测试你的程序，然后重复1~2步骤直到结果足够好。</li>
</ol>
<p><img src="./asset/1516630753816.png" alt=""><br>
<em>图1-1. 传统的方法</em></p>
<p>因为这个问题不是微不足道，因此你的程序看起来就像一张有许多复杂规则的长表------非常难以维护。</p>
<p>相反的，基于机器学习的垃圾邮件分类器能够通过检测垃圾邮件中经常出现而正常邮件中不常见的单词模式，自动地学会什么单词和短语能很好地用于垃圾邮件的预测（图1-2所示）。这个程序更加简短，也更容易维护，而且很有可能预测结果更加准确。</p>
<p><img src="./asset/1516632423698.png" alt="Alt text"><br>
<em>图1-2 机器学习的方式</em></p>
<p>此外，如果垃圾邮件发送者如果发现所有含 “4U” 的邮件都被拦截了，他们可能会开始用“For U” 来替代。用传统方法构建的邮件过滤器将不得不添加一条规则来过滤含 “For U” 的email。如果垃圾邮件发送者针对你的邮件过滤器继续修改，你也必须保证能随之添加新的过滤规则。</p>
<p>相反的，基于机器学习的邮件过滤器自动探测出含 “For U” 的邮件被用户标记为垃圾邮件的频率特别高，之后该过滤器不需要人工介入，就能开始对 “For U” 进行标记（图 1-3）。</p>
<p><img src="./asset/1516634844274.png" alt="Alt text"><br>
<em>图 1-3 自适应变化</em></p>
<p>另一个机器学习能够“发光发热”的领域是某些问题对于传统编程来说太过复杂或者根本没有已知的算法。比如说，语音识别：你要写一个简单的程序，能够根据你说的 “One” 或 “Two” 来将他们区分开来。你也许注意到单词 “Two” 是以高音开头（“T”），因此你可以写一个算法用于测试高音的强度，用这种方法来“One” 和 “Two” 。显然，这种方法并不能推广到成千上万的单词中，而每个人说话的口音也不一样，人们说话的时的环境可能有很多噪音，这些都使得用传统方式做语音识别变得不可能。最好的解决方案（就当前而言）是写一个能自我学习的算法，并提供大量的单词录音供其学习。</p>
<p>最后要说，其实机器学习还能够辅助人类进行学习（图 1-4）：我们可以检查机器学习算法来观察它们到底学到了什么（虽然对于一些算法来说不是很容易）。比如说，邮件分类器在训练了足够多的垃圾邮件之后，能够简单地获取它所认为的有利于预测垃圾邮件的单词列表。有时候，它能够揭示出未知的关联或者新趋势，由此更好地对问题进行理解。</p>
<p><img src="./asset/1516672220378.png" alt="Alt text"><br>
<em>图 1-4 机器学习能够辅助学习某些规律</em></p>
<p>总结来说，机器学习能够用于以下场景：</p>
<ul>
<li>解决某一问题需要花大量时间手动调整代码，或者是该问题有大量的规则：机器学习算法通常代码更简单，效果更好</li>
<li>某些复杂的问题如果使用传统编程方式的话，根本没有好的解决方案：最好的机器学习技术能够找到解决方案</li>
<li>变动的环境：机器学习系统能够根据新来采集的数据进行自我调整</li>
<li>某个复杂的问题有大量的数据，我们需要找到其中的某些规律</li>
</ul>
<h3 class="mume-header" id="%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%B3%BB%E7%BB%9F%E7%9A%84%E7%A7%8D%E7%B1%BB">机器学习系统的种类</h3>

<p>机器学习系统的种类非常多，我们需要根据以下的几点将它们分成几个大类：</p>
<ul>
<li>它们是不是在有人监督的情况下进行学习（分为监督学习、非监督学习、半监督学习、增强学习）</li>
<li>它们是不是能够在应用的同时逐渐地优化自身（分为在线学习和批量学习）</li>
<li>它们是简单地将新数据和原有数据进行比较来预测，还是像科学家一样从原有数据中发现某些特定的模式，并通过构建一个预测模型来对新数据进行预测（分为实例依赖和模型依赖）</li>
</ul>
<p>这些分类标准并不是绝对的，你可以用如何你喜欢的方式来组织它们。比如说，一个最先进的邮件分类器也许能够在应用的同时，将新的标有垃圾邮件或普通邮件的案例输入到一个神经网络模型中进行训练；这个系统就称为在线的、基于模型的监督学习系统。</p>
<p>让我们具体看看这些分类标准是什么。</p>
<h3 class="mume-header" id="%E7%9B%91%E7%9D%A3%E9%9D%9E%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0">监督/非监督学习</h3>

<p>机器学习系统能够根据在训练的过程中是否需要监督进行分类。主要可以分为4个类：监督学习，非监督学习，半监督学习和增强学习。</p>
<h4 class="mume-header" id="%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0">监督学习</h4>

<p>在监督学习中，你 “喂” 给机器学习算法的训练数据中包括了你希望得到的结果，称为标记（图 1-5）</p>
<p><img src="./asset/1516675587803.png" alt="Alt text"><br>
<em>图 1-5 监督学习的带标签训练集</em></p>
<p>一种典型的监督学习任务是 <em>分类</em>。邮件分类器就是分类的一个很好的例子：它通过很多带有类型信息（垃圾或者普通）的邮件来学习，之后用于新邮件的分类。</p>
<p>另一种典型的监督学习任务是预测一个数值，比如说一辆车的价格，提供的是大量的特征向量（将里程数、车龄、品牌等不同属性组合在一起成为一个特征向量），这种任务称为 <em>回归</em>（图 1-6）。在训练时，你需要给算法提供很多同时包含特征向量和标记（车的价格）的车的例子。</p>
<p><img src="./asset/1516678371874.png" alt="Alt text"><br>
<em>图 1-6 回归</em></p>
<blockquote>
<p>一个有趣事实是，<em>回归</em> 这个奇怪的名字原本是统计学的一个术语，最开始是Francis Galton 在研究孩子身高时引入，他发现如果一个孩子的父母都是高个子，孩子趋向于比他的父母都要矮，所以他称这种现象为 <em>回归于平均水平</em>。这个名词后来被他用于分析两个相关变量的方法中。</p>
</blockquote>
<p><img src="./asset/note.png" alt="Alt text"><br>
在机器学习中，一个 <em>属性</em> 通常是指一种类型的数据（例如里程数），而 <em>特征</em> 需要根据上下文来确定其具体的含义，但通常来说是指一个属性和它的值（例如：“里程数=15,000”）。很多人会将 <em>属性</em> 和 <em>特征</em> 混用。</p>
<p>**注意：**有的回归算法也会被用于分类，反之亦然。比如说，逻辑回归算法就是一种常见的将回归应用于分类的算法，其输出值为属于相应类的概率大小（例如：20%的可能是垃圾邮件）。</p>
<p>下面是一些最重要的监督学习算法（本书中涵盖的）：</p>
<ul>
<li>k-近邻</li>
<li>线性回归</li>
<li>逻辑回归</li>
<li>支持向量机</li>
<li>决策树和随机森林</li>
<li>神经网络</li>
</ul>
<blockquote>
<p>注意：有的神经网络可能是非监督学习，比如说自编码 (autoencoders)和 受限玻尔兹曼机。有的神经网络也可能是半监督的，比如 深度信念网络（Deep Belief Networks）和 非监督预训练（unsupervised pre-training）</p>
</blockquote>
<h4 class="mume-header" id="%E9%9D%9E%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0">非监督学习</h4>

<p>正如你所料，非监督学习的训练数据不提供标记（图 1-7）。系统在没有 “老师” 的情况下进行学习。<br>
<img src="./asset/1516687036244.png" alt="Alt text"><br>
<em>图 1-7 一个用于非监督学习的无标记训练集</em></p>
<p>下面是一些最重要的非监督学习算法（在第8章，我们将会讲解数据降维）：</p>
<ul>
<li>聚类
<ul>
<li>k-均值（k-Means）</li>
<li>层次聚类分析（Hierarchical Cluster Analysis，HCA）</li>
<li>最大期望算法（Expectation Maximization）</li>
</ul>
</li>
<li>数据降维和可视化
<ul>
<li>主成分分析（Principle Component Analysis，PCA）</li>
<li>核主成分分析（Kernel PCA）</li>
<li>局部线性嵌入（Locally-Linear Embedding，LLE）</li>
<li>t分布随机近邻嵌入（t-distribution stochastic neighbor embedding，t-SNE）</li>
</ul>
</li>
<li>关联规则学习
<ul>
<li>Apriori算法</li>
<li>Eclat算法</li>
</ul>
</li>
</ul>
<p>比如说，你有很多浏览你博客的访问者的数据，你可能希望运行一个聚类算法将相似的访问者划分为同一个组（图 1-8）。你没有对算法说明某个访问者应该属于哪个类，它完全自动地找到他们之间的关联。再比如，你发现访问者中40%是喜欢看连环画的男性，他们通常在晚上读你的博客，而20%是喜欢读科幻小说的年轻人，他们通常在周末浏览你的博客，等等。如果你使用层次聚类算法，还可能将每个组再细分为更小的组。这些信息可以帮助你针对每一个组推送他们喜欢的博文。</p>
<p><img src="./asset/1516690587393.png" alt="Alt text"><br>
<em>图 1-8 聚类</em></p>
<p>可视化算法也是非监督学习算法的一个很好的例子：你提供了大量复杂且无标记的数据，算法输出能够在2维或3维图像中非常容易显示的数据（图1-9）。这些算法尽可能多地保留数据原有的结构关系（例如：试图在可视化操作中保持分离的集群尽可能不重叠），让你能理解数据是如何组织的，并发现其中潜在的规律。<br>
<img src="./asset/1516691230759.png" alt="Alt text"><br>
<em>图 1-9 t-SNE 语义集群的高亮可视化显示</em></p>
<blockquote>
<p>从图中你可以看到，动物和交通工具有非常明显的分界，而 “horse” 与 “deer” 的距离要比其与 “bird” 的距离近，等等信息。图片来自于 Socher，Ganjoo，Manning 和 Ng (2013), &quot;T-SNE visualization of the semantic word space&quot;，已通过授权。</p>
</blockquote>
<p>与聚类相关的一个任务是 <em>数据降维</em>，目的是在简化数据的同时尽可能减少信息量的损失。一种实现方式是将多个相关的特征合并为一个特征。比如，车的里程数和车龄非常相关，因此可以把这两个特征合并成一个特征，表示车的磨损程度。这就称为 <em>特征提取</em> 。</p>
<p><strong>通常来说，在将数据交个某个机器学习算法（比如监督学习算法）进行训练之前，先用数据降维算法减小原始数据的维度是一个很好的想法。而且也能让训练的时间更短，数据占用的磁盘和内存资源更少，而且有时候能够获得更好的训练结果</strong></p>
<p>还有一个非监督学习的任务是 <em>异态检测</em>，例如：发现信用卡的非正常交易以预防诈骗，发现生产中的次品，在将数据集交个学习算法进行训练之前先删除其中的异常值。这个系统使用正常的实例进行训练，当一个新的实例到来，它能判断该实例是正常的还是异常的（见图 1-10）。<br>
<img src="./asset/1516694354177.png" alt="Alt text"><br>
<em>图 1-10 异态检测</em></p>
<p>最后一个常见的非监督学习任务是 <em>关联规则学习</em>，主要用于挖掘数据，发现各属性之间的有价值的关系。比如说，假设你开了一家超市，将你每一天的销售记录交给关联规则学习算法处理，可能会发现买了烧烤调料和薯片的人很可能同时买牛排。因此，你可以将这些商品放在一起，可能就会提高营业收入。</p>
<h4 class="mume-header" id="%E5%8D%8A%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0">半监督学习</h4>

<p>有的算法能够处理部分标记的训练数据，通常是大多数未标记，只有少量做了标记。这总算法就是半监督算法（图 1-11）。</p>
<p><img src="./asset/1516697460215.png" alt="Alt text"><br>
<em>图 1-11 半监督学习</em></p>
<p>某些图片托管服务，如 Google Photos，就是这种算法的一个例子。如果你向服务器上传了一张你的全家福照片，它就能自动识别其中的人，并指出某人A出现在第1、5、11张图片中，另一个人B出现在第2、5、7张图片中。这部分工作属于非监督学习算法（聚类）。现在，这个系统的工作是，在这张全家福的照片中指出他们分别是谁，即仅仅是对一个样本打上标签，它就能说出每一张照片上每个人的名字，这对照片的检索非常有用。</p>
<blockquote>
<p>注：上述情况只有在系统工作得非常完美时才会出现。但实际情况是，系统经常会给同一个人创建多个类别，或者有的时候在同一个类别中会有两个或多个看起来长得像的人，所以，你需要一些个人单独的照片，并且手动清除一些类别。</p>
</blockquote>
<p>大多数的半监督学习算法同时结合了非监督学习和监督学习算法。比如 <em>深度信念网络 (DBNS)</em> 就是在非监督算法 <em>受限玻尔兹曼机(RBMs)</em> 的基础上再加一层或多层的 RBMs，以非监督的方式按顺序用RBMs进行训练，之后，整个系统使用监督学习的方法进行调优。</p>
<h4 class="mume-header" id="%E5%A2%9E%E5%BC%BA%E5%AD%A6%E4%B9%A0">增强学习</h4>

<p>和之前的机器学习算法相比，增强学习绝对是一个异类。在该学习系统中，有一个称为 <em>代理</em> 的模块，能够对当前的环境进行 “观察”，选择并执行某个动作，并返回一个奖励（或者是返回一个惩罚作为消极的反馈，如图 1-12）。系统必须能够自动地学会什么是最佳的动作，称为策略，即获得奖励最多的那个动作。一个策略指定了在某种给定的情形下，代理应该如何选择。</p>
<p><img src="./asset/1516704325739.png" alt="Alt text"><br>
<em>图 1-12 增强学习</em></p>
<p>举例来说，许多的机器人都实现了增强学习算法用于学会走路。DeepMind项目的AlphaGo程序就是增强学习的一个很好的例子：它在2016年3月的时候，凭借着战胜世界围棋冠军的李世石而一举成名。它通过分析上百万的围棋对弈过程，学到了赢棋的策略，之后开始与自身进行对弈。在真正的对弈开始时，系统并不进行学习，而是将其已经学到的策略进行应用。</p>
<h3 class="mume-header" id="%E6%89%B9%E9%87%8F%E5%AD%A6%E4%B9%A0%E5%92%8C%E5%9C%A8%E7%BA%BF%E5%AD%A6%E4%B9%A0">批量学习和在线学习</h3>

<p>另一种用于对机器学习进行分类的标准是：随着在数据流的不断到来，系统能否循序渐进地改善自身的性能。</p>
<h4 class="mume-header" id="%E6%89%B9%E9%87%8F%E5%AD%A6%E4%B9%A0">批量学习</h4>

<p><em>批量学习</em> 并不具备循序渐进改善自身的能力：它在训练时，必须一次性输入所有当前可得到的数据。通常来说，这需要花费大量的时间和计算资源，因此它通常是离线进行的。首先，完成对系统的训练，接下来讲系统安装到生产环境中，并且在应用的过程中不再进行学习；它只是简单地将学到的 “知识” 进行应用，这也叫做 <em>离线学习</em>。</p>
<p>如果你希望批量学习系统能够正确处理 “变种” 的数据（比如出现了新的垃圾邮件模式），你需要从头开始用所有的数据重新训练一个新版本的系统（不仅仅是新的数据，而且也要包括原有数据），之后，用新训练的系统替换掉老系统。</p>
<p>幸运的是，整个过程包括训练、性能评估、系统的更换都能非常简单地自动化进行（如图 1-3 所示），所以批量学习也能够适应不断变化的数据。只要根据需求，定期地更新训练数据并从头开始训练一个新版本的系统即可。</p>
<p>这种解决方案通常来说简单并且有效，但是用所有的数据进行训练很可能需要花费数个小时，所以你通常只是每24小时或者是每个星期训练一个新的系统。如果你的系统需要快速适应不断变化的数据（比如预测股票价格），那你就需要一个使系统进化更快的解决方案。</p>
<p>另外，训练所有的数据需要大量的计算资源（CPU、内存空间、磁盘空间、网络资源等等）。如果训练集中的数据量非常大，而你的系统需要每天都从头开始进行自动训练，它最终将消耗你大量的资金。如果数据的量超级巨大，那使用批量学习根本就是不现实的。</p>
<p>最后，如果你的批量学习系统安装在一个资源有限的设备上（如智能手机或火星探测器），每天带着大量的训练数据，占用大量资源训练训练多个小时，那么这个设备估计其他什么事情都干不了了。</p>
<p>幸运的是，在上述那些尴尬的情况下，我们可以使用接下来介绍的算法实现循环渐进的学习。</p>
<h4 class="mume-header" id="%E5%9C%A8%E7%BA%BF%E5%AD%A6%E4%B9%A0">在线学习</h4>

<p>在线学习系统中，你可以将数据一个一个，或者一小组一小组地 “喂” 给你的系统（每一小组称为 <em>小批</em> ），你系统的性能也在你喂食的过程中渐渐得到优化。这样学习的每一步都非常快速，代价也小，因此系统能够在运行的同时，对新来的数据进行学习（见图 1-13）。</p>
<p><img src="./asset/1516711944382.png" alt="Alt text"><br>
<em>图 1-13 在线学习</em></p>
<p>在线学习算法非常适合于数据以流的方式连续不断到来的系统（如股票的价格）和需要快速适应改变的系统。当然，如果你只有为数不多的计算资源，那么在线学习也是一个很好的选择：一旦在线学习系统学过了新的实例，它就不需要再次学习该实例，你可以直接将该实例丢弃（除非你想要将系统回退到之前的某个状态，并对数据进行重现）。这将节约大量的系统空间。</p>
<p>当训练数据量非常大时，也许我们设备的存储空间不能容纳下全部的训练数据，那么我们也可以使用在线学习算法（这也称为 <em>核外学习</em>）。算法只将部分的数据进行加载，先针对这些数据进行训练，之后重复这一过程，直到所有的数据都被训练过（见图 1-14）。</p>
<p><img src="./asset/1516713013659.png" alt="Alt text"><br>
<em>图 1-14 以在线学习的方式处理超大的数据集</em></p>
<p><img src="./asset/warning.png" alt="Alt text"><br>
<strong>特别注意：上述的所有过程通常是离线进行的（系统并不处于运行状态），所以 <em>在线学习</em> 这个名字总感觉令人困惑，你就认为它是 <em>增量式学习</em> 好了。</strong></p>
<p>在线学习系统中一个重要的参数是，在线学习应该以多快来适应新数据：这称为学习速率。如果你设置了一个高学习率，你的系统将能够快速适应新数据，但它也将很快 “忘记” 旧数据（你应该不会想要一个只能将与最新接收到的邮件类型相同的邮件标注出来的系统吧）。相反地，如果你设置了一个低学习率，系统将有更大的惯性，也就是说：它学得更慢，但同时对新数据中的噪声、非典型的数据点序列不敏感。</p>
<p>在线学习的一大挑战是：如果坏的数据被输入到系统中，系统的性能将会渐渐地下降。如果是在线运行的系统，这种变化将会被你的客户注意到。例如，坏的数据可能来自于机器人上出故障的传感器，或者是某人对搜索引擎进行狂轰滥炸地输入某个搜索词以提高该词在搜索结果中的排名。为了减少这些风险，你需要密切监视你的系统，在你发现系统的性能下降时及时停止学习（如果可能的话，最好将系统回退到之前的某个工作状态）。你最好也能够对输入数据进行监视，剔除其中的异常数据（例如使用异常检测算法）。</p>
<h3 class="mume-header" id="%E5%9F%BA%E4%BA%8E%E5%AE%9E%E4%BE%8B-vs-%E5%9F%BA%E4%BA%8E%E6%A8%A1%E5%9E%8B">基于实例 VS 基于模型</h3>

<p>另一种区分机器学习系统的方法是根据问题------它们是怎么被构建起来的。绝大多数的机器学习任务都是关于预测的，这就意味着在给了一些训练数据进行训练之后，系统能够对它之前从未见过的实例进行归纳。对训练数据表现出不错的性能是很好，但这还不够，我们真正的目标是对新到来的实例能够有好的性能。</p>
<p>归纳的方式主要有两种：基于实例学习 和 基于模型学习。</p>
<h4 class="mume-header" id="%E5%9F%BA%E4%BA%8E%E5%AE%9E%E4%BE%8B%E5%AD%A6%E4%B9%A0">基于实例学习</h4>

<p>也许，最平常的学习方式是仅仅通过 “死记硬背” 的方式来学习。如果你构建的是这样的一个邮件过滤器，它将只能标记出那些与被用户标记过的邮件相同的邮件，不是最坏的模型，但绝对不会是最好的模型。</p>
<p>除了能够标记出与已知的垃圾文件完全相同的邮件外，你的邮件分类器还应该能够标记出与已知垃圾邮件非常相似的邮件。这就要求系统能够测试出两封邮件之间的相似度。一种非常基本的测试方案是计算两封邮件之间相同的单词的数量。如果新邮件中有大量的单词与已知垃圾邮件中的单词相同，就可以将该新邮件打上标记。</p>
<p>这就是 <em>基于实例的学习</em> ：系统记下所有的实例，之后用相似度对新的实例进行归纳（图 1-15）</p>
<p><img src="./asset/1516718784735.png" alt="Alt text"><br>
<em>图1-15 基于实例的学习</em></p>
<h4 class="mume-header" id="%E5%9F%BA%E4%BA%8E%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0">基于模型学习</h4>

<p>另一种方式是，从一个实例集中归纳出一般的规律，针对这些实例构建出一个模型，之后用这个模型进行预测，这就称为 <em>基于模型的学习</em>（图 1-16）<br>
<img src="./asset/1516719129963.png" alt="Alt text"><br>
<em>图 1-16 基于模型的学习</em></p>
<p>比方说你想要知道是否金钱真的能够使人开心，你可以从 <a href="https://goo.gl/0Eht9W">OECD's website</a> 上面下载 <em>更好生活指数</em>，同时从 <a href="http://goo.gl/j1MSKe">IMF's websit</a> 下载对应国家的国内人均GDP。之后，你将这两个数据合并到同一个表中，并以人均GDP从高到底进行排列，表1-1 摘录了你所得到的表的一部分：</p>
<p><em>表 1-1 金钱真的使人更快乐吗？</em><br>
<img src="./asset/1516719585370.png" alt="Alt text"></p>
<p>让我们随机地取一部分数据以散点图的形式进行显示（图 1-17）：<br>
<img src="./asset/1516719680145.png" alt="Alt text"><br>
<em>图 1-17 你看到某种趋势了吗？</em></p>
<p>上图看起来确实有某种趋势。虽然数据有一些噪声（比如局部数据是随机分布的），不过整体上看，似乎人们的生活满意度随着各自国家人均GDP的上升而线性增长。所以，你决定建立一个生活满意度和人均GDP间呈线性函数关系的模型，这一步就成为 <em>模型选择</em>：你只选择人均GDP这一属性为生活满意度建立线性模型（等式 1-1）</p>
<p>        <em>等式 1-1. 一个简单的线性模型</em></p>
<p>        <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>l</mi><mi>i</mi><mi>f</mi><mi>e</mi><mi mathvariant="normal">_</mi><mi>s</mi><mi>a</mi><mi>t</mi><mi>i</mi><mi>s</mi><mi>f</mi><mi>a</mi><mi>c</mi><mi>a</mi><mi>t</mi><mi>i</mi><mi>o</mi><mi>n</mi><mo>=</mo><msub><mi>θ</mi><mn>0</mn></msub><mo>+</mo><msub><mi>θ</mi><mn>1</mn></msub><mo>×</mo><mi>G</mi><mi>D</mi><mi>P</mi><mi mathvariant="normal">_</mi><mi>p</mi><mi>e</mi><mi>r</mi><mi mathvariant="normal">_</mi><mi>c</mi><mi>a</mi><mi>p</mi><mi>i</mi><mi>t</mi><mi>a</mi></mrow><annotation encoding="application/x-tex">life\_satisfacation=\theta_0+\theta_1\times GDP\_per\_capita</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.69444em;"></span><span class="strut bottom" style="height:1.00444em;vertical-align:-0.31em;"></span><span class="base"><span class="mord mathit" style="margin-right:0.01968em;">l</span><span class="mord mathit">i</span><span class="mord mathit" style="margin-right:0.10764em;">f</span><span class="mord mathit">e</span><span class="mord mathrm" style="margin-right:0.02778em;">_</span><span class="mord mathit">s</span><span class="mord mathit">a</span><span class="mord mathit">t</span><span class="mord mathit">i</span><span class="mord mathit">s</span><span class="mord mathit" style="margin-right:0.10764em;">f</span><span class="mord mathit">a</span><span class="mord mathit">c</span><span class="mord mathit">a</span><span class="mord mathit">t</span><span class="mord mathit">i</span><span class="mord mathit">o</span><span class="mord mathit">n</span><span class="mrel">=</span><span class="mord"><span class="mord mathit" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathrm mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"></span></span></span></span></span><span class="mbin">+</span><span class="mord"><span class="mord mathit" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathrm mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"></span></span></span></span></span><span class="mbin">×</span><span class="mord mathit">G</span><span class="mord mathit" style="margin-right:0.02778em;">D</span><span class="mord mathit" style="margin-right:0.13889em;">P</span><span class="mord mathrm" style="margin-right:0.02778em;">_</span><span class="mord mathit">p</span><span class="mord mathit">e</span><span class="mord mathit" style="margin-right:0.02778em;">r</span><span class="mord mathrm" style="margin-right:0.02778em;">_</span><span class="mord mathit">c</span><span class="mord mathit">a</span><span class="mord mathit">p</span><span class="mord mathit">i</span><span class="mord mathit">t</span><span class="mord mathit">a</span></span></span></span></p>
<p>这个模型有两个模型参数，<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>θ</mi><mn>0</mn></msub></mrow><annotation encoding="application/x-tex">\theta_0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.69444em;"></span><span class="strut bottom" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="base"><span class="mord"><span class="mord mathit" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathrm mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"></span></span></span></span></span></span></span></span> 和 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>θ</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">\theta_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.69444em;"></span><span class="strut bottom" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="base"><span class="mord"><span class="mord mathit" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathrm mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"></span></span></span></span></span></span></span></span>。通过调整这些参数，你可以得到任何你想表示的线性函数，如图 1-18 所示。<br>
<img src="./asset/1516760088927.png" alt="Alt text"><br>
<em>图 1-18 若干可能的线性模型</em></p>
<p>在你使用你的模型前，必须先确定参数 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>θ</mi><mn>0</mn></msub></mrow><annotation encoding="application/x-tex">\theta_0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.69444em;"></span><span class="strut bottom" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="base"><span class="mord"><span class="mord mathit" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathrm mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"></span></span></span></span></span></span></span></span> 和 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>θ</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">\theta_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.69444em;"></span><span class="strut bottom" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="base"><span class="mord"><span class="mord mathit" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathrm mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"></span></span></span></span></span></span></span></span> 的值。那你确定你所取得参数值能够使模型的性能最好呢？为了回答这个问题，你需要先明确性能测量的方式。你既可以定义一个 <em>效用函数</em>（或称为 <em>适配函数</em>）来测量你的模型有多好，也可以定义一个 <em>代价函数</em> 来测量你的模型有差。就线性回归问题而言，通常使用线性模型的预测值和训练样本的实际值之间的欧式距离作为代价函数。训练的目标就是最小化这个距离。</p>
<p>线性回归算法的工作原理是：你将训练数据交给它，它负责找出一组模型的参数，这组参数能够使你的线性模型与数据吻合得最好，这个过程就称为 <em>训练</em>模型。在我们这个例子中，算法发现最佳的参数值是 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>θ</mi><mn>0</mn></msub><mo>=</mo><mn>4</mn><mi mathvariant="normal">.</mi><mn>8</mn><mn>5</mn></mrow><annotation encoding="application/x-tex">\theta_0=4.85</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.69444em;"></span><span class="strut bottom" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="base"><span class="mord"><span class="mord mathit" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathrm mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"></span></span></span></span></span><span class="mrel">=</span><span class="mord mathrm">4</span><span class="mord mathrm">.</span><span class="mord mathrm">8</span><span class="mord mathrm">5</span></span></span></span>，<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>θ</mi><mn>1</mn></msub><mo>=</mo><mn>4</mn><mi mathvariant="normal">.</mi><mn>9</mn><mn>1</mn><mo>×</mo><mn>1</mn><msup><mn>0</mn><mrow><mo>−</mo><mn>5</mn></mrow></msup></mrow><annotation encoding="application/x-tex">\theta_1=4.91\times10^{-5}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.8141079999999999em;"></span><span class="strut bottom" style="height:0.964108em;vertical-align:-0.15em;"></span><span class="base"><span class="mord"><span class="mord mathit" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathrm mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"></span></span></span></span></span><span class="mrel">=</span><span class="mord mathrm">4</span><span class="mord mathrm">.</span><span class="mord mathrm">9</span><span class="mord mathrm">1</span><span class="mbin">×</span><span class="mord mathrm">1</span><span class="mord"><span class="mord mathrm">0</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">−</span><span class="mord mathrm mtight">5</span></span></span></span></span></span></span></span></span></span></span></span>。</p>
<p>现在，这个模型与训练数据吻合得最好（对线性模型而言），如图 1-19所示：<br>
<img src="./asset/1516761258332.png" alt="Alt text"><br>
<em>图 1-19 与给定数据最吻合的线性模型</em></p>
<p>你可以使用该模型进行数据预测了：你想要知道塞浦路斯人的幸福指数，但在 OECD网站上并没有给出答案。幸运的是，你可以使用你训练好的模型进行预测：先获取塞浦路斯的人均GDP，为 22587美元 ，将这个值代入你的模型就可以得到他们的生活满意度应该大致为 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mn>4</mn><mi mathvariant="normal">.</mi><mn>8</mn><mn>5</mn><mo>+</mo><mn>2</mn><mn>2</mn><mn>5</mn><mn>8</mn><mn>7</mn><mo>×</mo><mn>4</mn><mi mathvariant="normal">.</mi><mn>9</mn><mn>1</mn><mo>×</mo><mn>1</mn><msup><mn>0</mn><mrow><mo>−</mo><mn>5</mn></mrow></msup><mo>=</mo><mn>5</mn><mi mathvariant="normal">.</mi><mn>9</mn><mn>6</mn></mrow><annotation encoding="application/x-tex">4.85+22587\times4.91\times10^{-5}=5.96</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.8141079999999999em;"></span><span class="strut bottom" style="height:0.897438em;vertical-align:-0.08333em;"></span><span class="base"><span class="mord mathrm">4</span><span class="mord mathrm">.</span><span class="mord mathrm">8</span><span class="mord mathrm">5</span><span class="mbin">+</span><span class="mord mathrm">2</span><span class="mord mathrm">2</span><span class="mord mathrm">5</span><span class="mord mathrm">8</span><span class="mord mathrm">7</span><span class="mbin">×</span><span class="mord mathrm">4</span><span class="mord mathrm">.</span><span class="mord mathrm">9</span><span class="mord mathrm">1</span><span class="mbin">×</span><span class="mord mathrm">1</span><span class="mord"><span class="mord mathrm">0</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">−</span><span class="mord mathrm mtight">5</span></span></span></span></span></span></span></span></span><span class="mrel">=</span><span class="mord mathrm">5</span><span class="mord mathrm">.</span><span class="mord mathrm">9</span><span class="mord mathrm">6</span></span></span></span> 。</p>
<p>为了满足你的好奇心，例1-1 中的Python代码实现了数据的加载，预处理，将数据以散点图的形式进行可视化，之后进行线性模型的训练，最后将完成训练的模型用于预测。</p>
<blockquote>
<p>注：如果你不理解其中的代码也没有关系，在接下来的章节我们就会介绍Scikit-Learn库。</p>
</blockquote>
<p><em>例 1-1. 用Scikit-Learn训练并运行一个线性模型</em></p>
<pre class="language-python"><span class="token keyword">import</span> matplotlib
<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd
<span class="token keyword">from</span> sklearn <span class="token keyword">import</span> linear_model
<span class="token keyword">from</span> sklearn <span class="token keyword">import</span> neighbors

<span class="token comment" spellcheck="true"># 数据加载</span>
oecd_bli <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span><span class="token string">"oecd_bli_2015.csv"</span><span class="token punctuation">,</span> thousands<span class="token operator">=</span><span class="token string">","</span><span class="token punctuation">)</span>
gdp_per_capita <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span><span class="token string">"gdp_per_capita.csv"</span><span class="token punctuation">,</span> thousands<span class="token operator">=</span><span class="token string">","</span><span class="token punctuation">,</span>
    delimiter<span class="token operator">=</span><span class="token string">"\t"</span><span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">'latin1'</span><span class="token punctuation">,</span> na_values<span class="token operator">=</span><span class="token string">"n/a"</span><span class="token punctuation">)</span>
<span class="token comment" spellcheck="true"># 数据的预处理 假定函数 perpare_country_stats已经完成定义</span>
<span class="token comment" spellcheck="true"># 用于将 GDP和生活满意度合并到同一个Pandas dataframe</span>
country_stats <span class="token operator">=</span> prepare_country_stats<span class="token punctuation">(</span>oecd_bli<span class="token punctuation">,</span> gdp_per_capita<span class="token punctuation">)</span>
X <span class="token operator">=</span> np<span class="token punctuation">.</span>c_<span class="token punctuation">[</span>country_stats<span class="token punctuation">[</span><span class="token string">"GDP per capita"</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
y <span class="token operator">=</span> np<span class="token punctuation">.</span>c_<span class="token punctuation">[</span>country_stats<span class="token punctuation">[</span><span class="token string">"Life satisfaction"</span><span class="token punctuation">]</span><span class="token punctuation">]</span>

<span class="token comment" spellcheck="true"># 数据的可视化</span>
country_stats<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>kind<span class="token operator">=</span><span class="token string">"scatter"</span><span class="token punctuation">,</span> x<span class="token operator">=</span><span class="token string">"GDP per capita"</span><span class="token punctuation">,</span>
    y<span class="token operator">=</span><span class="token string">"Life satisfaction"</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># 选择一个线性模型</span>
clf <span class="token operator">=</span> linear_model<span class="token punctuation">.</span>LinearRegression<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># 训练模型</span>
clf<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>X<span class="token punctuation">,</span> y<span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># 对塞浦路斯进行预测</span>
X_new <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">22587</span><span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token comment" spellcheck="true"># 塞浦路斯的人均GDP</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>clf<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>X_new<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># 输出为 [[ 5.96242338]]</span>
</pre>
<p><img src="./asset/note.png" alt="Alt text"><br>
如果你使用基于实例的学习算法就会发现，斯洛文尼亚和塞浦路斯的人均GDP最接近，而斯洛文尼亚在OECD上显示的生活幸福指数是5.7，因此，你的算法也许会预测塞浦路斯的生活幸福指数也是5.7。如果你把观察的范围扩大到最接近的3个国家，你将发现葡萄牙和西班牙的幸福指数分别为5.1 和 6.5。求这3个国家的幸福指数的平均值，可以得到5.77，已经非常接近使用基于模型算法得到的预测值。这种简单的算法被称为 <em>k-近邻</em> 回归（在这个例子中，k=3）。<br>
如果用k-近邻实现代码也非常简单，只需要将之前的代码：<br>
<code>clf = linear_model.LinearRegression()</code><br>
替换为：<br>
<code>clf = neighbors.KNeighborsRegressor(n_neighbors=3)</code><br>
即可。</p>
<p>如果顺利的话，你的模型可以做出很好的预测。否则，你可能需要更多的属性（如就业率、健康、空气污染等），也可以是选择更多或质量更好的训练数据，或者是更加强大的模型（比如说是多项式回归模型）。</p>
<p>总结来说：</p>
<ul>
<li>你需要数据进行分析</li>
<li>你需要选择一个学习模型</li>
<li>你需要使用训练数据对其进行训练（比如说，学习算法需要找到使代价函数最小的一组模型参数）</li>
<li>最后，你将这个训练好的模型应用到对新实例的预测中（这个过程称为推断），并期望得到好的结果</li>
</ul>
<p>这就是典型的基于模型学习算法的工作流程。在第二章中，通过实践一个端到端的项目，你将会有更加直接的体验。</p>
<p>到目前为止，我们介绍了很多的机器学习分类，你应该找到了：机器学习到底是什么？它为什么非常有用？机器学习系统最常见的分类有哪些？典型的项目工作流程是怎样的？那么，让我们看看哪些因素会导致训练失败，预测结果不准确。</p>
<h3 class="mume-header" id="%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E4%B8%BB%E8%A6%81%E6%8C%91%E6%88%98">机器学习的主要挑战</h3>

<p>简而言之，你的主要工作是选择一个学习算法和将数据给这个算法训练，因此训练失败的元素也分为两类：“选了不合适的算法” 和 “数据不好”。让我们先来看看坏数据的一个例子。</p>
<h4 class="mume-header" id="%E8%AE%AD%E7%BB%83%E6%95%B0%E6%8D%AE%E4%B8%8D%E5%85%85%E8%B6%B3">训练数据不充足</h4>

<p>对于一个三岁小孩来说，要让他认识什么是苹果，只需要手指指着一个苹果说 “苹果” 就可以了（也许需要多次重复这个过程）。之后，小孩就能分辨出任何颜色、任何形状的苹果了。真是天才！</p>
<p>机器学习就不是这样了，几乎所有的机器学习要能正常工作都需要大量的数据。即使是非常简单的问题，你也需要提供上千个实例，而对于复杂的问题，如图像或语音识别，你可能需要上百万个实例（除非你能找到一个已经存在的，和你问题相似的模型）。</p>
<h5 class="mume-header" id="%E6%95%B0%E6%8D%AE%E4%B8%8D%E5%8F%AF%E6%80%9D%E8%AE%AE%E7%9A%84%E8%83%BD%E5%8A%9B">数据不可思议的能力</h5>

<p>2001年，微软的研究员Michele Banko 和 Eric Brill 发表了一篇著名的论文，在这篇论文中展示了一些非比寻常的机器学习算法，其中包括一个非常简单，只需要足够的数据量，就能解决复杂的自然语言歧义问题（例如：是单词“to”，还是“two”，还是“too” 需要根据上下文确定），如图 1-20所示：<br>
<img src="./asset/1516780410208.png" alt="Alt text"><br>
<em>图 1-20 数据和算法的重要性</em></p>
<p>作者提出：这些结果让我们重新思考，是应该花大量的时间和金钱来改进发展算法还是将这些时间和金钱用于语料库的开发。</p>
<p>2009年，Peter Norvig 等人发表了一篇标题为 《数据不可思议的有效性》的论文，他们都认为对于复杂的问题而言，数据远比算法来的重要。但需要注意的是，小型或者中型的数据集仍然非常普遍，而且并不总是能够简单地获得额外的训练数据，所以，抛弃算法还为时过早。</p>
<h4 class="mume-header" id="%E9%9D%9E%E5%85%B8%E5%9E%8B%E8%AE%AD%E7%BB%83%E6%95%B0%E6%8D%AE">非典型训练数据</h4>

<p>为了得到较好的泛化性能（预测结果），你的训练数据对你想要预测的实例具有代表性就显得非常重要，这不管是对基于模型的训练还是基于实例的训练都成立。</p>
<p>比如说之前预测满意度的那个例子，如果我们使用的数据集并不是具有代表性的（之前我们把一些国家的数据去掉了，现在把它们补回来），散点图如 1-21：<br>
<img src="./asset/1516781831639.png" alt="Alt text"></p>

      </div>
      <div class="md-sidebar-toc"><ul>
<li><a href="#%E7%94%A8scikit-learn%E5%92%8Ctensorflow%E5%AE%9E%E8%B7%B5%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0">用Scikit-Learn和TensorFlow实践机器学习</a>
<ul>
<li><a href="#%E5%89%8D%E8%A8%80">前言</a>
<ul>
<li><a href="#%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%B5%B7%E5%95%B8">机器学习的海啸</a></li>
<li><a href="#%E4%BD%A0%E9%A1%B9%E7%9B%AE%E4%B8%AD%E7%9A%84%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0">你项目中的机器学习</a></li>
<li><a href="#%E7%9B%AE%E6%A0%87%E5%92%8C%E6%96%B9%E6%B3%95">目标和方法</a></li>
<li><a href="#%E5%89%8D%E6%8F%90">前提</a></li>
<li><a href="#%E8%B7%AF%E6%A0%87">路标</a></li>
<li><a href="#%E5%85%B6%E4%BB%96%E8%B5%84%E6%BA%90">其他资源</a></li>
<li><a href="#%E6%9C%AC%E4%B9%A6%E4%B8%AD%E4%BD%BF%E7%94%A8%E7%9A%84%E6%83%AF%E4%BE%8B">本书中使用的惯例</a></li>
<li><a href="#%E4%BD%BF%E7%94%A8%E4%BB%A3%E7%A0%81%E7%A4%BA%E4%BE%8B">使用代码示例</a></li>
<li><a href="#oreilly-safari">O'Reilly Safari</a></li>
<li><a href="#%E5%A6%82%E4%BD%95%E8%81%94%E7%B3%BB%E6%88%91%E4%BB%AC">如何联系我们</a></li>
<li><a href="#%E9%B8%A3%E8%B0%A2">鸣谢</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#%E7%AC%AC%E4%B8%80%E9%83%A8%E5%88%86-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80">第一部分 机器学习基础</a>
<ul>
<li><a href="#%E7%AC%AC%E4%B8%80%E7%AB%A0-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%BA%B5%E8%A7%88">第一章 机器学习纵览</a>
<ul>
<li><a href="#%E4%BB%80%E4%B9%88%E6%98%AF%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0">什么是机器学习？</a></li>
<li><a href="#%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0">为什么要用机器学习</a></li>
<li><a href="#%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%B3%BB%E7%BB%9F%E7%9A%84%E7%A7%8D%E7%B1%BB">机器学习系统的种类</a></li>
<li><a href="#%E7%9B%91%E7%9D%A3%E9%9D%9E%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0">监督/非监督学习</a>
<ul>
<li><a href="#%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0">监督学习</a></li>
<li><a href="#%E9%9D%9E%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0">非监督学习</a></li>
<li><a href="#%E5%8D%8A%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0">半监督学习</a></li>
<li><a href="#%E5%A2%9E%E5%BC%BA%E5%AD%A6%E4%B9%A0">增强学习</a></li>
</ul>
</li>
<li><a href="#%E6%89%B9%E9%87%8F%E5%AD%A6%E4%B9%A0%E5%92%8C%E5%9C%A8%E7%BA%BF%E5%AD%A6%E4%B9%A0">批量学习和在线学习</a>
<ul>
<li><a href="#%E6%89%B9%E9%87%8F%E5%AD%A6%E4%B9%A0">批量学习</a></li>
<li><a href="#%E5%9C%A8%E7%BA%BF%E5%AD%A6%E4%B9%A0">在线学习</a></li>
</ul>
</li>
<li><a href="#%E5%9F%BA%E4%BA%8E%E5%AE%9E%E4%BE%8B-vs-%E5%9F%BA%E4%BA%8E%E6%A8%A1%E5%9E%8B">基于实例 VS 基于模型</a>
<ul>
<li><a href="#%E5%9F%BA%E4%BA%8E%E5%AE%9E%E4%BE%8B%E5%AD%A6%E4%B9%A0">基于实例学习</a></li>
<li><a href="#%E5%9F%BA%E4%BA%8E%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0">基于模型学习</a></li>
</ul>
</li>
<li><a href="#%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E4%B8%BB%E8%A6%81%E6%8C%91%E6%88%98">机器学习的主要挑战</a>
<ul>
<li><a href="#%E8%AE%AD%E7%BB%83%E6%95%B0%E6%8D%AE%E4%B8%8D%E5%85%85%E8%B6%B3">训练数据不充足</a>
<ul>
<li><a href="#%E6%95%B0%E6%8D%AE%E4%B8%8D%E5%8F%AF%E6%80%9D%E8%AE%AE%E7%9A%84%E8%83%BD%E5%8A%9B">数据不可思议的能力</a></li>
</ul>
</li>
<li><a href="#%E9%9D%9E%E5%85%B8%E5%9E%8B%E8%AE%AD%E7%BB%83%E6%95%B0%E6%8D%AE">非典型训练数据</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
      <a id="sidebar-toc-btn">≡</a>
    </body>
    
    
    
    
    
    <script>
(function bindTaskListEvent() {
  var taskListItemCheckboxes = document.body.getElementsByClassName('task-list-item-checkbox')
  for (var i = 0; i < taskListItemCheckboxes.length; i++) {
    var checkbox = taskListItemCheckboxes[i]
    var li = checkbox.parentElement
    if (li.tagName !== 'LI') li = li.parentElement
    if (li.tagName === 'LI') {
      li.classList.add('task-list-item')
    }
  }
}())    
</script>
    
<script>

var sidebarTOCBtn = document.getElementById('sidebar-toc-btn')
sidebarTOCBtn.addEventListener('click', function(event) {
  event.stopPropagation()
  if (document.body.hasAttribute('html-show-sidebar-toc')) {
    document.body.removeAttribute('html-show-sidebar-toc')
  } else {
    document.body.setAttribute('html-show-sidebar-toc', true)
  }
})
</script>
      
  </html>